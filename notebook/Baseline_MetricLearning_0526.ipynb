{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Baseline_MetricLearning_0526.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4eb3df024534187bdc1d7f4d91075ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42e7971303654ba6903aa335351f0855",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2218550e42b49d0885ef928c6213c12",
              "IPY_MODEL_10502500cd0342b787210276e83b2f78"
            ]
          }
        },
        "42e7971303654ba6903aa335351f0855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2218550e42b49d0885ef928c6213c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a1ae566e54e4149bb255aa134b32c1f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22c5316dcf064692ab589cfa87660c62"
          }
        },
        "10502500cd0342b787210276e83b2f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ce588cc7c694787a9541ac879de7671",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.38MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29334a77544d4d038273ba9010b33abf"
          }
        },
        "5a1ae566e54e4149bb255aa134b32c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22c5316dcf064692ab589cfa87660c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ce588cc7c694787a9541ac879de7671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29334a77544d4d038273ba9010b33abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d96Tn9SNxTF",
        "colab_type": "text"
      },
      "source": [
        "## ベースラインモデル概要\n",
        "\n",
        "- Forumに挙がっているコードを、Pytorchで出来る限り再現したコード\n",
        "    - https://mp.weixin.qq.com/s/KBtxmYlvV1U7wimCyv9v_g?\n",
        "    - https://github.com/Ai-Light/KDD2020Multimodalities/blob/master/code/%5Bimage-concat-query%5D-wwm_uncased_L12-768_v3_quart.ipynb\n",
        "    \n",
        "\n",
        "- 訓練データの画像とクエリのペアを正例、ペアをランダムに入れ替えたデータを負例として、2値分類モデルを学習するモデル\n",
        "    - クエリ側：BERTとword2vecでエンコードしたものをconcat\n",
        "    - 画像側：面積順にして、画特徴量と位置特徴量とクラスラベルをconcatして、BiLSTMでエンコード\n",
        "    - 最後に、両方をconcatして、全結合層でつなげて、出力\n",
        "    \n",
        "    \n",
        "    - 負例に関しては、ミニバッチごとに、ミニバッチ数×5の負例（ランダムに入れ替え）を用意\n",
        "\n",
        "\n",
        "\n",
        "- 現在評価中だが、1epochが約5時間(GPU2枚)で、3epochで、0.5くらいな感じ\n",
        "- 多分、まだ上がるはず\n",
        "    - Epoch 1, train_loss: 0.21015196827693125, train_score: 0.9234113280874952, valid_score: 0.45962303517930975, time: 19286.304292201996\n",
        "    - Epoch 2, train_loss: 0.18031329249707034, train_score: 0.9534390202407629, valid_score: 0.4747285933335644, time: 19173.962506055832\n",
        "    - Epoch 3, train_loss: 0.17171741712500027, train_score: 0.9565376569179256, valid_score: 0.5024780766046713, time: 19172.145148277283"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_z0MENqSwCX",
        "colab_type": "code",
        "outputId": "f3110fe7-d749-43e1-b1f3-d9280e07e1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_azqvH__RTc-",
        "outputId": "35a5a4e5-ae41-42a5-d967-d5ab76cb34c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install swifter\n",
        "!pip install pytorch-metric-learning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: swifter in /usr/local/lib/python3.6/dist-packages (0.304)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /usr/local/lib/python3.6/dist-packages (from swifter) (5.7.0)\n",
            "Requirement already satisfied: parso>0.4.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (0.7.0)\n",
            "Requirement already satisfied: numba>=0.49.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (0.49.1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (1.0.3)\n",
            "Requirement already satisfied: dask[complete]>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (2.12.0)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (4.41.1)\n",
            "Requirement already satisfied: bleach>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from swifter) (3.1.5)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (7.5.1)\n",
            "Requirement already satisfied: llvmlite<=0.33.0.dev0,>=0.31.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.49.0->swifter) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.49.0->swifter) (46.3.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba>=0.49.0->swifter) (1.18.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->swifter) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->swifter) (2018.9)\n",
            "Requirement already satisfied: fsspec>=0.6.0; extra == \"complete\" in /usr/local/lib/python3.6/dist-packages (from dask[complete]>=0.19.0->swifter) (0.7.4)\n",
            "Requirement already satisfied: partd>=0.3.10; extra == \"complete\" in /usr/local/lib/python3.6/dist-packages (from dask[complete]>=0.19.0->swifter) (1.1.0)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1; extra == \"complete\" in /usr/local/lib/python3.6/dist-packages (from dask[complete]>=0.19.0->swifter) (1.3.0)\n",
            "Requirement already satisfied: distributed>=2.0; extra == \"complete\" in /usr/local/lib/python3.6/dist-packages (from dask[complete]>=0.19.0->swifter) (2.16.0)\n",
            "Requirement already satisfied: PyYaml; extra == \"complete\" in /usr/local/lib/python3.6/dist-packages (from dask[complete]>=0.19.0->swifter) (3.13)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"complete\" in /usr/local/lib/python3.6/dist-packages (from dask[complete]>=0.19.0->swifter) (0.10.0)\n",
            "Requirement already satisfied: bokeh>=1.0.0; extra == \"complete\" in /usr/local/lib/python3.6/dist-packages (from dask[complete]>=0.19.0->swifter) (1.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (20.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (1.12.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->swifter) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->swifter) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->swifter) (5.0.6)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->swifter) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->swifter) (4.3.3)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.6/dist-packages (from partd>=0.3.10; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (0.2.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (1.6.0)\n",
            "Collecting tornado>=5; python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/84/119a46d494f008969bf0c775cb2c6b3579d3c4cc1bb1b41a022aa93ee242/tornado-6.0.4.tar.gz (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (2.0.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (1.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (7.1.2)\n",
            "Requirement already satisfied: contextvars; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (2.4)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/dist-packages (from distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (2.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (2.11.2)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh>=1.0.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (7.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach>=3.1.1->swifter) (2.4.7)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (5.2.2)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (5.3.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (4.6.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->swifter) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (0.8.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/dist-packages (from zict>=0.1.3->distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (1.0.1)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars; python_version < \"3.7\"->distributed>=2.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (0.14)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh>=1.0.0; extra == \"complete\"->dask[complete]>=0.19.0->swifter) (1.1.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.8.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->swifter) (19.0.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->swifter) (0.1.9)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->swifter) (0.6.0)\n",
            "Building wheels for collected packages: tornado\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-6.0.4-cp36-cp36m-linux_x86_64.whl size=427635 sha256=f63abcc4c83cddb427f33358bc34775ba0bb7688fd9e90a46f093bd8a97a8e22\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/84/2f/409c7b2bb3afc3aa727f7ee8787975e0793f74d1165f4d0104\n",
            "Successfully built tornado\n",
            "Installing collected packages: tornado\n",
            "  Found existing installation: tornado 4.5.3\n",
            "    Uninstalling tornado-4.5.3:\n",
            "      Successfully uninstalled tornado-4.5.3\n",
            "Successfully installed tornado-6.0.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tornado"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-metric-learning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/d5/5dd5f07a8f69d6538db9a720158bfeee0d9107b63988250b15c84cc59ac1/pytorch_metric_learning-0.9.86-py3-none-any.whl (74kB)\n",
            "\r\u001b[K     |████▍                           | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-metric-learning) (4.41.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pytorch-metric-learning) (0.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-metric-learning) (1.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-metric-learning) (1.5.0+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pytorch-metric-learning) (0.22.2.post1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pytorch-metric-learning) (7.0.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pytorch-metric-learning) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pytorch-metric-learning) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pytorch-metric-learning) (0.15.1)\n",
            "Installing collected packages: pytorch-metric-learning\n",
            "Successfully installed pytorch-metric-learning-0.9.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m2nQtsuaQ7sr",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import logging\n",
        "import json\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "\n",
        "import base64\n",
        "import swifter\n",
        "import gensim\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import lightgbm as lgb\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "#import japanize_matplotlib\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "pd.set_option('display.max_columns', 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KS9idpUtQ7tB",
        "outputId": "a4b534c2-8a84-4cae-d0c6-fd54d610a482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pytorch_metric_learning import losses\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
        "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
        "    get_cosine_schedule_with_warmup,DistilBertTokenizer,DistilBertModel\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "ERROR:root:The testing module requires faiss. You can install the GPU version with the command 'conda install faiss-gpu -c pytorch' \n",
            "                        or the CPU version with 'conda install faiss-cpu -c pytorch'. Learn more at https://github.com/facebookresearch/faiss/blob/master/INSTALL.md\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CCJ2XhAS7cE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/data/train/'\n",
        "VALID_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/data/valid/'\n",
        "TESTA_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/data/testA/'\n",
        "TESTB_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/data/testB/'\n",
        "FEATURE_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/features/'\n",
        "LOG_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/log/'\n",
        "W2V_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/w2v/'\n",
        "MODEL_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/model/'\n",
        "SUBMIT_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/prediction_result/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G0raUpbyRM9k",
        "colab": {}
      },
      "source": [
        "# DATA_DIR = '/home/m_fujitsuka/mnt/data/'\n",
        "# TRAIN_DIR = '/home/m_fujitsuka/mnt/data/'\n",
        "# VALID_DIR = '/home/m_fujitsuka/mnt/data/'\n",
        "# TESTA_DIR = '/home/m_fujitsuka/mnt/data/'\n",
        "# TESTB_DIR = '/home/m_fujitsuka/mnt/data/'\n",
        "\n",
        "# FEATURE_DIR = '/home/m_fujitsuka/mnt/fujitsuka/features/'\n",
        "# LOG_DIR = '/home/m_fujitsuka/mnt/fujitsuka/log/'\n",
        "# W2V_DIR = '/home/m_fujitsuka/mnt/fujitsuka/w2v/'\n",
        "# MODEL_DIR = '/home/m_fujitsuka/mnt/fujitsuka/model/'\n",
        "# SUBMIT_DIR = '/home/m_fujitsuka/mnt/fujitsuka/prediction_result/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NKWPOtZ8Q7tw"
      },
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TsD8ScdkQ7tz",
        "colab": {}
      },
      "source": [
        "# # train = pd.read_csv(TRAIN_DIR+'train.tsv', sep='\\t', , quoting=csv.QUOTE_NONE)\n",
        "# train = pd.read_csv(TRAIN_DIR+'train.sample.tsv', sep='\\t')\n",
        "# print(train.shape)\n",
        "# train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pZtQFPJ_Q7uG",
        "colab": {}
      },
      "source": [
        "# valid = pd.read_csv(VALID_DIR+'valid.tsv', sep='\\t')\n",
        "# print(valid.shape)\n",
        "# valid.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IQuRGN4iQ7uU",
        "colab": {}
      },
      "source": [
        "# testA = pd.read_csv(TESTA_DIR+'testA.tsv', sep='\\t')\n",
        "# print(testA.shape)\n",
        "# testA.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LK0eNvPyQ7uk"
      },
      "source": [
        "### Decode Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A7xfGrBxQ7uo",
        "colab": {}
      },
      "source": [
        "# def transform_boxes(df_row):\n",
        "#     return np.frombuffer(base64.b64decode(df_row.boxes), dtype=np.float32).reshape(df_row.num_boxes, 4)\n",
        "\n",
        "# def transform_features(df_row):\n",
        "#     return np.frombuffer(base64.b64decode(df_row.features), dtype=np.float32).reshape(df_row.num_boxes, 2048)\n",
        "\n",
        "# def transform_class_labels(df_row):\n",
        "#     return np.frombuffer(base64.b64decode(df_row.class_labels), dtype=np.int64).reshape(df_row.num_boxes)\n",
        "\n",
        "# def transform_df(df):\n",
        "#     df.boxes = df.swifter.apply(transform_boxes, axis=1)\n",
        "#     df.features = df.swifter.apply(transform_features, axis=1)\n",
        "#     df.class_labels = df.swifter.apply(transform_class_labels, axis=1)\n",
        "#     return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gShMk_awQ7vE",
        "colab": {}
      },
      "source": [
        "# train = transform_df(train)\n",
        "# valid = transform_df(valid)\n",
        "# testA = transform_df(testA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbvwNvRrNxTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # すでにデコードしたデータも作成済み\n",
        "# # こちらだと、メモリ消費量102GBくらいで、読み込みも速い\n",
        "\n",
        "# train = pd.read_pickle(FEATURE_DIR+'train_decode.pkl')\n",
        "# valid = pd.read_pickle(FEATURE_DIR+'valid_decode.pkl')\n",
        "# testA = pd.read_pickle(FEATURE_DIR+'testA_decode.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GdXGQ2cUQ7vS"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GZzx7nadQ7vU"
      },
      "source": [
        "- 正規化したボックスの座標"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zTNq3GdLO_iR",
        "colab": {}
      },
      "source": [
        "# train['box_normalized'] = train.swifter.apply(lambda x: np.array([[xi[0]/x.image_h,xi[1]/x.image_w,xi[2]/x.image_h,xi[3]/x.image_w] for xi in x.boxes]), axis=1)\n",
        "# valid['box_normalized'] = valid.swifter.apply(lambda x: np.array([[xi[0]/x.image_h,xi[1]/x.image_w,xi[2]/x.image_h,xi[3]/x.image_w] for xi in x.boxes]), axis=1)\n",
        "# testA['box_normalized'] = testA.swifter.apply(lambda x: np.array([[xi[0]/x.image_h,xi[1]/x.image_w,xi[2]/x.image_h,xi[3]/x.image_w] for xi in x.boxes]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8akM00eSNxTp",
        "colab_type": "text"
      },
      "source": [
        "- 正規化されたボックスの面積"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jdRtu_5zQ7vX",
        "colab": {}
      },
      "source": [
        "# train['box_area_normalized'] = train.box_normalized.apply(lambda x: np.array([(xi[3]-xi[1]) * (xi[2]-xi[0]) for xi in x]))\n",
        "# valid['box_area_normalized'] = valid.box_normalized.apply(lambda x: np.array([(xi[3]-xi[1]) * (xi[2]-xi[0]) for xi in x]))\n",
        "# testA['box_area_normalized'] = testA.box_normalized.apply(lambda x: np.array([(xi[3]-xi[1]) * (xi[2]-xi[0]) for xi in x]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jg5QdYu5Q7vj"
      },
      "source": [
        "- ボックスのクラスラベルをテキスト化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vqV6V3G0Q7vm",
        "colab": {}
      },
      "source": [
        "# class_label_dict = {\n",
        "#     0:'top clothes (coat, jacket, shirt, etc.)',\n",
        "#     1:'skirt & dress',\n",
        "#     2:'bottom clothes (trousers, pants, etc.)',\n",
        "#     3:'luggage, leather goods',\n",
        "#     4:'shoes',\n",
        "#     5:'accessories (jewelry, clothing accessories, belts, hats, scarves, etc.)',\n",
        "#     6:'snacks, nuts, liquor and tea',\n",
        "#     7:'makeup, perfume, beauty tools and essential oils',\n",
        "#     8:'bottle drink',\n",
        "#     9:'furniture',\n",
        "#     10:'stationery',\n",
        "#     11:'household electrical appliances',\n",
        "#     12:'home decoration',\n",
        "#     13:'household fabric',\n",
        "#     14:'kitchenware',\n",
        "#     15:'home / personal cleaning tools',\n",
        "#     16:'storage supplies',\n",
        "#     17:'motorcycle, motorcycle accessories, vehicles, bicycle and riding equipment',\n",
        "#     18:'outdoor product',\n",
        "#     19:'lighting',\n",
        "#     20:'toys',\n",
        "#     21:'underwear',\n",
        "#     22:'digital supplies',\n",
        "#     23:'bed linens',\n",
        "#     24:'baby products',\n",
        "#     25:'personal care',\n",
        "#     26:'sporting goods',\n",
        "#     27:'clothes (accessories, baby clothing, etc.)',\n",
        "#     28:'others',\n",
        "#     29:'human face',\n",
        "#     30:'arm',\n",
        "#     31:'hair',\n",
        "#     32:'hand',\n",
        "# }\n",
        "\n",
        "# train['class_labels_words'] = train.class_labels.swifter.apply(lambda x: (' ').join([class_label_dict[xi] for xi in x]))\n",
        "# valid['class_labels_words'] = valid.class_labels.swifter.apply(lambda x: (' ').join([class_label_dict[xi] for xi in x]))\n",
        "# testA['class_labels_words'] = testA.class_labels.swifter.apply(lambda x: (' ').join([class_label_dict[xi] for xi in x]))\n",
        "\n",
        "# train['class_labels'] = train.class_labels.swifter.apply(lambda x: np.array([class_label_dict[xi] for xi in x]))\n",
        "# valid['class_labels'] = valid.class_labels.swifter.apply(lambda x: np.array([class_label_dict[xi] for xi in x]))\n",
        "# testA['class_labels'] = testA.class_labels.swifter.apply(lambda x: np.array([class_label_dict[xi] for xi in x]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW7N0pfhNxTw",
        "colab_type": "text"
      },
      "source": [
        "- 今回のテキストデータに対するtokenizer\n",
        "- 学習済みword2vecの重み行列"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UeTqja5iQ7v3",
        "colab": {}
      },
      "source": [
        "# def get_coefs(word, *arr):\n",
        "#     return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "# def load_embeddings(path):\n",
        "#     with open(path, encoding='utf-8') as f:\n",
        "#         return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n",
        "\n",
        "# def build_matrix(word_index, path):\n",
        "#     embedding_index = load_embeddings(path)\n",
        "#     embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "#     unknown_words = []\n",
        "    \n",
        "#     for word, i in word_index.items():  # word_indexのwordに対応するembがあれば、embを代入する\n",
        "#         try:\n",
        "#             embedding_matrix[i] = embedding_index[word]\n",
        "#         except KeyError:\n",
        "#             unknown_words.append(word)\n",
        "#     return embedding_matrix, unknown_words\n",
        "\n",
        "\n",
        "# def load_word_embed(word_embed_glove=W2V_DIR+\"glove.840B.300d.txt\", \n",
        "#                     word_embed_crawl=W2V_DIR+\"crawl-300d-2M.vec\",\n",
        "#                     save_filename=W2V_DIR+\"word_embedding_matrix_testA\",\n",
        "#                     word_index=None):\n",
        "    \n",
        "    \n",
        "    \n",
        "#     if os.path.exists(save_filename + \".npy\"):\n",
        "#         embedding_matrix = np.load(save_filename + \".npy\").astype(\"float32\")\n",
        "\n",
        "#         with open(W2V_DIR+'tokenizer_w2v.pkl', 'rb') as f:\n",
        "#             Tokenizer = pickle.load(f)\n",
        "\n",
        "#     else:\n",
        "\n",
        "#         # Tokneizerの学習\n",
        "#         Tokenizer = keras.preprocessing.text.Tokenizer(filters='', lower=False)\n",
        "#         Tokenizer.fit_on_texts(list(train['query'])+list(valid['query'])+list(testA['query'])\n",
        "#                                 +list(train['class_labels_words'])+list(valid['class_labels_words'])+list(testA['class_labels_words']))\n",
        "        \n",
        "#         with open(W2V_DIR+'tokenizer_w2v.pkl', 'wb') as f:\n",
        "#             pickle.dump(Tokenizer, f)\n",
        "        \n",
        "#         if word_index is None:\n",
        "#             word_index = Tokenizer.word_index\n",
        "        \n",
        "#         glove_matrix, unknown_words_glove = build_matrix(word_index, word_embed_glove)\n",
        "#         print('n unknown words (glove): ', len(unknown_words_glove))\n",
        "        \n",
        "#         crawl_matrix, unknown_words_crawl = build_matrix(word_index, word_embed_crawl)\n",
        "#         print('n unknown words (crawl): ', len(unknown_words_crawl))\n",
        "        \n",
        "#         embedding_matrix = crawl_matrix + glove_matrix  \n",
        "#         np.save(save_filename, embedding_matrix)\n",
        "\n",
        "#         del crawl_matrix\n",
        "#         del glove_matrix\n",
        "#         gc.collect()\n",
        "        \n",
        "#     return embedding_matrix, Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hlQvm9zjQ7wD",
        "colab": {}
      },
      "source": [
        "# # about 5 minites\n",
        "# embedding_matrix, tokenizer_w2v = load_word_embed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFPKFcLRXJ_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train.to_pickle(FEATURE_DIR+'train.pkl')\n",
        "# valid.to_pickle(FEATURE_DIR+'valid.pkl')\n",
        "# testA.to_pickle(FEATURE_DIR+'testA.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sge3ZaE0NxT1",
        "colab_type": "text"
      },
      "source": [
        "## 上記の処理が終わっている前提で"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPX4sV3nNxT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 上記の処理済みデータは作成済み\n",
        "# メモリ消費量102GBくらいで、読み込みも速い\n",
        "\n",
        "train = pd.read_pickle(FEATURE_DIR+'train.pkl')\n",
        "valid = pd.read_pickle(FEATURE_DIR+'valid.pkl')\n",
        "testA = pd.read_pickle(FEATURE_DIR+'testA.pkl')\n",
        "\n",
        "embedding_matrix = np.load(W2V_DIR+\"word_embedding_matrix_testA.npy\").astype(\"float32\")\n",
        "\n",
        "with open(W2V_DIR+'tokenizer_w2v_sample.pkl', 'rb') as f:\n",
        "    tokenizer_w2v = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WAMB3K6TQ7xn"
      },
      "source": [
        "## モデル構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cuUmn9HBPT7B",
        "colab": {}
      },
      "source": [
        "# ログ作成\n",
        "logger = logging.getLogger('main')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "sc = logging.StreamHandler()\n",
        "logger.addHandler(sc)\n",
        "fh = logging.FileHandler(LOG_DIR+'20200525log')\n",
        "logger.addHandler(fh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vx7jmHxZQ7xr",
        "colab": {}
      },
      "source": [
        "# シード値固定\n",
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O8cHgIhXQ7x0",
        "outputId": "e2f2c1c8-a8ab-4ec0-e1ca-e6aad6caaacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# GPU使うために\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#device = 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ubdQYpFeQ7x_"
      },
      "source": [
        "### DatasetとDataLoaderの設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FFjriqwvQ7yA",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 14  # クエリの最大単語数\n",
        "MAX_LEN_IMG = 10  # 検出ボックスの最大数\n",
        "MAX_LABEL_IMG = 8  # 検出ボックスのクラスラベルに含まれるwordの最大数\n",
        "\n",
        "class KDDDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, train_mode=True, transform=None):\n",
        "        self.df = df\n",
        "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.w2v_tokenizer = tokenizer_w2v\n",
        "        #self.transform = transform\n",
        "        self.train_mode = train_mode\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        ################################################################\n",
        "        # query side\n",
        "        ################################################################\n",
        "        query = row['query']\n",
        "        \n",
        "        # BERTの入力作成\n",
        "        inputs_query = self.bert_tokenizer.encode_plus(\n",
        "            query,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "        )\n",
        "        \n",
        "        ids_query = inputs_query[\"input_ids\"]\n",
        "        token_type_ids_query = inputs_query[\"token_type_ids\"]\n",
        "        mask_query = inputs_query[\"attention_mask\"]\n",
        "        \n",
        "        padding_len = MAX_LEN - len(ids_query)\n",
        "        ids_query =  ([0]*padding_len) + ids_query\n",
        "        token_type_ids_query = ([0]*padding_len) + token_type_ids_query\n",
        "        mask_query = ([0]*padding_len) + mask_query\n",
        "            \n",
        "            \n",
        "        # word2vec入力作成\n",
        "        query = tokenizer_w2v.texts_to_sequences([query])\n",
        "        query = pad_sequences(query, maxlen=MAX_LEN, padding='pre')[0]\n",
        "\n",
        "        \n",
        "        ################################################################\n",
        "        # image side\n",
        "        ################################################################\n",
        "\n",
        "        # box_areaの大きい順にソート\n",
        "        box_area = row['box_area_normalized']\n",
        "        box_area_ordered = list(np.argsort(box_area)[::-1])\n",
        "        \n",
        "        \n",
        "        features_ordered = row.features[box_area_ordered, :][:MAX_LEN_IMG][:,::-1]\n",
        "        box_ordered = row.box_normalized[box_area_ordered, :][:MAX_LEN_IMG][:,::-1]\n",
        "        area_ordered = row.box_area_normalized[box_area_ordered][:MAX_LEN_IMG][::-1]\n",
        "        class_labels_ordered = row.class_labels[box_area_ordered][:MAX_LEN_IMG][::-1]\n",
        "        class_labels = []\n",
        "        for cl in class_labels_ordered:\n",
        "            class_tmp = tokenizer_w2v.texts_to_sequences([cl])[0][:MAX_LABEL_IMG]\n",
        "            class_labels.append([0]*(MAX_LABEL_IMG-len(class_tmp)) + class_tmp)\n",
        "\n",
        "        pad_image_len = MAX_LEN_IMG - features_ordered.shape[0]\n",
        "        img_mask = ([0]*pad_image_len) + [1 for _ in range(features_ordered.shape[0])]\n",
        "\n",
        "\n",
        "        features = pad_sequences([features_ordered.reshape(-1,2048)], maxlen=MAX_LEN_IMG, padding='pre')[0]\n",
        "        box = pad_sequences([box_ordered.reshape(-1,4)], maxlen=MAX_LEN_IMG, padding='pre')[0]\n",
        "        area = pad_sequences([area_ordered.reshape(-1,1)], maxlen=MAX_LEN_IMG, padding='pre')[0]\n",
        "        class_labels = pad_sequences([class_labels], maxlen=MAX_LEN_IMG, padding='pre')[0]\n",
        "\n",
        "        \n",
        "        if self.train_mode:\n",
        "            return {\n",
        "                'query': torch.tensor(query, dtype=torch.long),\n",
        "                'ids_query': torch.tensor(ids_query, dtype=torch.long),\n",
        "                'token_type_ids_query': torch.tensor(token_type_ids_query, dtype=torch.long),\n",
        "                'mask_query': torch.tensor(mask_query, dtype=torch.long),\n",
        "                'features': torch.tensor(features, dtype=torch.float),\n",
        "                'box': torch.tensor(box, dtype=torch.float),\n",
        "                'area': torch.tensor(area, dtype=torch.float),\n",
        "                'class_labels': torch.tensor(class_labels, dtype=torch.long).view(MAX_LEN_IMG, MAX_LABEL_IMG),\n",
        "                'img_mask': torch.tensor(img_mask, dtype=torch.float).view(MAX_LEN_IMG,1),\n",
        "            }\n",
        "        else:\n",
        "            # 今は何も変わっていない\n",
        "            return {\n",
        "                'query': torch.tensor(query, dtype=torch.long),\n",
        "                'ids_query': torch.tensor(ids_query, dtype=torch.long),\n",
        "                'token_type_ids_query': torch.tensor(token_type_ids_query, dtype=torch.long),\n",
        "                'mask_query': torch.tensor(mask_query, dtype=torch.long),\n",
        "                'features': torch.tensor(features, dtype=torch.float),\n",
        "                'box': torch.tensor(box, dtype=torch.float),\n",
        "                'area': torch.tensor(area, dtype=torch.float),\n",
        "                'class_labels': torch.tensor(class_labels, dtype=torch.long).view(MAX_LEN_IMG, MAX_LABEL_IMG),\n",
        "                'img_mask': torch.tensor(img_mask, dtype=torch.float).view(MAX_LEN_IMG,1),\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xvkO9HhiQ7yW",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# # dataloaderの挙動確認\n",
        "\n",
        "# dataset_train = KDDDataset(train, train_mode=True)\n",
        "# train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0, drop_last=True)\n",
        "\n",
        "# for i, batch in enumerate(train_loader):\n",
        "#     if i<1:\n",
        "#         print(batch['query'].shape)\n",
        "#         print(batch['ids_query'].shape)\n",
        "#         print(batch['features'].shape)\n",
        "#         print(batch['box'].shape)\n",
        "#         print(batch['area'].shape)\n",
        "#         print(batch['class_labels'].shape)\n",
        "#         print(batch['img_mask'].shape)\n",
        "\n",
        "#     else:\n",
        "#         break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "87pW9Hat2nBm"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Aw_dQ6JQIS2",
        "colab": {}
      },
      "source": [
        "class KDDModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KDDModel, self).__init__()\n",
        "        self.model_name = 'KDDModel'\n",
        "        \n",
        "        ######################################\n",
        "        # query \n",
        "        ######################################\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.max_feature = embedding_matrix.shape[0]\n",
        "        self.embedding_size = embedding_matrix.shape[1]\n",
        "        self.embedding = nn.Embedding(self.max_feature, self.embedding_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.required_grad = True  # こっちもtrainableに\n",
        "\n",
        "        self.lstm_q = nn.LSTM(self.embedding_size, hidden_size=64, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "        \n",
        "        \n",
        "        ######################################\n",
        "        # image\n",
        "        ######################################\n",
        "        self.conv1d = nn.Conv1d(in_channels=300, out_channels=128, kernel_size=3)\n",
        "\n",
        "        self.fc_i1 = nn.Linear(2048+128, 512)\n",
        "        self.fc_i2 = nn.Linear(5, 512)\n",
        "\n",
        "        self.lstm_i = nn.LSTM(512+512, hidden_size=512, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(768+64*2+512*2, 2048)\n",
        "        # self.fc2 = nn.Linear(2048, 512)\n",
        "        # self.fc3 = nn.Linear(512, 128)\n",
        "        # self.fc4 = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, query, ids, token_type_ids, mask, features, box, area, class_labels, img_mask):\n",
        "\n",
        "        ######################################\n",
        "        # query \n",
        "        ######################################\n",
        "        layers, pool_out = self.bert_model(input_ids=ids, token_type_ids=token_type_ids, attention_mask=mask)\n",
        "        layers = layers[:,-1,:]\n",
        "       \n",
        "        out_query = self.embedding(query).squeeze()\n",
        "        out_query, _  = self.lstm_q(out_query)\n",
        "        out_query = out_query[:,-1,:]  # bi-directionalなので、hidden_size*2\n",
        "        \n",
        "        out_query = torch.cat([layers, out_query], dim=-1)  # (batch, 768+128)\n",
        "\n",
        "\n",
        "        ######################################\n",
        "        # image\n",
        "        ######################################\n",
        "        class_labels = self.embedding(class_labels)\n",
        "        out_class_labels = torch.zeros((class_labels.shape[0], class_labels.shape[1], 128), requires_grad=True).to(device)\n",
        "        for l in range(class_labels.shape[1]):\n",
        "            out_class_labels[:,l,:] = F.max_pool1d(self.conv1d(class_labels[:,l,:,:].permute(0,2,1)), kernel_size=6).squeeze()\n",
        "        \n",
        "\n",
        "        out_image = torch.cat([out_class_labels, features], dim=-1)\n",
        "        out_image = F.relu(self.fc_i1(out_image))\n",
        "        out_image = out_image * img_mask\n",
        "\n",
        "        out_pos = torch.cat([box, area], dim=-1)\n",
        "        out_pos = out_pos * img_mask\n",
        "        out_pos = F.relu(self.fc_i2(out_pos))\n",
        "        \n",
        "        out_image = torch.cat([out_image, out_pos], dim=-1)\n",
        "        out_image, _ = self.lstm_i(out_image)  # bi-directionalなので、output_dimは*2\n",
        "        out_image = out_image * img_mask\n",
        "        #out_image = out_image[:,-1,:]\n",
        "        out_image = F.max_pool1d(out_image.transpose(1,2), kernel_size=out_image.size()[1]).squeeze()\n",
        "\n",
        "\n",
        "        \n",
        "        ######################################\n",
        "        # 結合\n",
        "        ######################################\n",
        "        out = torch.cat([out_query, out_image], dim=-1)\n",
        "        out = self.fc1(out)\n",
        "        # out = F.relu(self.fc2(out))\n",
        "        # out = F.relu(self.fc3(out))\n",
        "        # out = self.fc4(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SEph059mQ7zQ"
      },
      "source": [
        "### エポックごとバッチごとの学習・評価処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0lD5g25aqG6b",
        "colab": {}
      },
      "source": [
        "def train_model(train_loader, model, optimizer, criterion): #, scheduler):\n",
        "    model.train()\n",
        "    avg_loss = 0.\n",
        "    avg_score = 0.\n",
        "    for idx, batch in enumerate(tqdm(train_loader)):\n",
        "        batch_size = batch['query'].shape[0]\n",
        "\n",
        "        query = batch['query'].to(device)\n",
        "        ids_query = batch['ids_query'].to(device)\n",
        "        token_type_ids_query = batch['token_type_ids_query'].to(device)\n",
        "        mask_query = batch['mask_query'].to(device)\n",
        "        features = batch['features'].to(device)\n",
        "        box = batch['box'].to(device)\n",
        "        area = batch['area'].to(device)\n",
        "        class_labels = batch['class_labels'].to(device)\n",
        "        img_mask = batch['img_mask'].to(device)\n",
        "        \n",
        "        \n",
        "        ####################################################################\n",
        "        # Negative sample作成\n",
        "        # ここでは、バッチサイズの正例に、バッチサイズ*5の負例を加えている\n",
        "        ####################################################################\n",
        "        k = 5\n",
        "        for num in range(k):\n",
        "            idx_neg = random.sample(range(batch_size), k=batch_size)\n",
        "            #idx_neg = random.choices(range(batch_size), k=batch_size)\n",
        "            \n",
        "            query = torch.cat([query, batch['query'].to(device)], dim=0)\n",
        "            ids_query = torch.cat([ids_query, batch['ids_query'].to(device)], dim=0)\n",
        "            token_type_ids_query = torch.cat([token_type_ids_query, batch['token_type_ids_query'].to(device)], dim=0)\n",
        "            mask_query = torch.cat([mask_query, batch['mask_query'].to(device)], dim=0)\n",
        "            \n",
        "            features = torch.cat([features, batch['features'][idx_neg, :].to(device)])\n",
        "            box = torch.cat([box, batch['box'][idx_neg, :].to(device)], dim=0)\n",
        "            area = torch.cat([area, batch['area'][idx_neg, :].to(device)], dim=0)\n",
        "            class_labels = torch.cat([class_labels, batch['class_labels'][idx_neg, :].to(device)], dim=0)\n",
        "            img_mask = torch.cat([img_mask, batch['img_mask'][idx_neg, :].to(device)], dim=0)\n",
        "\n",
        "\n",
        "        labels = torch.cat([torch.tensor(np.ones(batch_size), dtype=torch.long), torch.tensor(np.zeros(batch_size*k), dtype=torch.long)], dim=0).to(device)\n",
        "        \n",
        "\n",
        "        out = model(query, ids_query, token_type_ids_query, mask_query, features, box, area, class_labels, img_mask)\n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        # score = roc_auc_score(labels.detach().cpu().numpy(), out[:,1].detach().cpu().numpy())\n",
        "        # print('roc_auc', score)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "        # avg_score += score / len(train_loader)\n",
        "\n",
        "        del out,loss\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return avg_loss#, avg_score\n",
        "\n",
        "\n",
        "\n",
        "def test_model(test_loader, model):\n",
        "    model.eval()\n",
        "    \n",
        "    out_list = []   \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(tqdm(test_loader)):\n",
        "            query = batch['query'].to(device)\n",
        "            ids_query = batch['ids_query'].to(device)\n",
        "            token_type_ids_query = batch['token_type_ids_query'].to(device)\n",
        "            mask_query = batch['mask_query'].to(device)\n",
        "            features = batch['features'].to(device)\n",
        "            box = batch['box'].to(device)\n",
        "            area = batch['area'].to(device)\n",
        "            class_labels = batch['class_labels'].to(device)\n",
        "            img_mask = batch['img_mask'].to(device)\n",
        "\n",
        "            out = F.softmax(model(query, ids_query, token_type_ids_query, mask_query, features, box, area, class_labels, img_mask), dim=-1)[:,1]\n",
        "\n",
        "            out_list.append(out)\n",
        "            del out\n",
        "        \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return out_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvwtx_EnNxUF",
        "colab_type": "text"
      },
      "source": [
        "### n-DCG@5の評価コード\n",
        "- Forumの公式のコードを流用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o8RExWGGOwT5",
        "colab": {}
      },
      "source": [
        "# compute dcg@k for a single sample\n",
        "def dcg_at_k(r, k):\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        return r[0] + np.sum(r[1:] / np.log2(np.arange(3, r.size + 2)))\n",
        "    return 0.\n",
        "\n",
        "\n",
        "# compute ndcg@k (dcg@k / idcg@k) for a single sample\n",
        "def get_ndcg(r, ref, k):\n",
        "    dcg_max = dcg_at_k(ref, k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    dcg = dcg_at_k(r, k)\n",
        "    return dcg / dcg_max\n",
        "\n",
        "\n",
        "def make_score(df_test, out_list):\n",
        "    for i, out in enumerate(out_list):\n",
        "        if i==0:\n",
        "            out_array = out.squeeze()\n",
        "        else:\n",
        "            out_array = torch.cat([out_array, out.squeeze()], dim=-1)\n",
        "\n",
        "    out_array = out_array.cpu().detach().numpy()\n",
        "    df_test['score'] = out_array\n",
        "    \n",
        "    # sort and group by\n",
        "    df_test = df_test.sort_values(by=\"score\", ascending=False)\n",
        "    grouped = df_test.groupby(\"query_id\").head(5)\n",
        "    \n",
        "    predictions = {}\n",
        "    for i, q_id in enumerate(tqdm(grouped['query_id'].unique())):\n",
        "        predictions[f'{q_id}'] = grouped.loc[(grouped['query_id']==q_id), 'product_id'].values.astype(str)\n",
        "    \n",
        "    \n",
        "    # read ground-truth\n",
        "    reference = json.load(open(VALID_DIR+'valid_answer.json'))\n",
        "\n",
        "    # compute score for each query\n",
        "    k = 5\n",
        "    score_sum = 0.\n",
        "    for qid in reference.keys():\n",
        "        ground_truth_ids = set([str(pid) for pid in reference[qid]])\n",
        "        ref_vec = [1.0] * len(ground_truth_ids)\n",
        "        pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions[qid]]\n",
        "        score_sum += get_ndcg(pred_vec, ref_vec, k)\n",
        "    # the higher score, the better\n",
        "    score = score_sum / len(reference)\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsjKPT_JNxUH",
        "colab_type": "text"
      },
      "source": [
        "### 実際に学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rQKLYducDw3E",
        "outputId": "386ca9f8-2a28-44d6-f5be-a630b5e5f50b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "e4eb3df024534187bdc1d7f4d91075ef",
            "42e7971303654ba6903aa335351f0855",
            "f2218550e42b49d0885ef928c6213c12",
            "10502500cd0342b787210276e83b2f78",
            "5a1ae566e54e4149bb255aa134b32c1f",
            "22c5316dcf064692ab589cfa87660c62",
            "5ce588cc7c694787a9541ac879de7671",
            "29334a77544d4d038273ba9010b33abf"
          ]
        }
      },
      "source": [
        "model = KDDModel().to(device)\n",
        "# model = nn.DataParallel(model) # これでGPU複数並列処理可能\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "from pytorch_metric_learning import losses\n",
        "criterion = losses.TripletMarginLoss(margin=0.1)\n",
        "\n",
        "loss_list_epoch_train = []\n",
        "score_list_epoch_valid = []\n",
        "score_best = 0\n",
        "patience = 0\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    start_time   = time.time()\n",
        "\n",
        "    dataset_train = KDDDataset(train, train_mode=True)\n",
        "    dataset_valid = KDDDataset(valid, train_mode=False)\n",
        "    train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0, drop_last=True)\n",
        "    valid_loader = DataLoader(dataset_valid, batch_size=128, shuffle=False, num_workers=0, drop_last=False)\n",
        "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
        "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
        "\n",
        "    loss_train, score_train = train_model(train_loader, model, optimizer, criterion) #, scheduler)\n",
        "    #scheduler.step()\n",
        "    # out_valid = test_model(valid_loader, model)\n",
        "    # score_valid = make_score(valid, out_valid)\n",
        "\n",
        "    loss_list_epoch_train.append(loss_train)\n",
        "    # score_list_epoch_valid.append(score_valid)\n",
        "\n",
        "    logger.info(f'Epoch {(epoch+1)}, train_loss: {loss_train}, time: {(time.time()-start_time)}')\n",
        "    # logger.info(f'Epoch {(epoch+1)}, train_loss: {loss_train}, train_score: {score_train}, valid_score: {score_valid}, time: {(time.time()-start_time)}')\n",
        "\n",
        "    \n",
        "    # # Eearly Stopping\n",
        "    # if score_valid > score_best:\n",
        "    #     score_best = score_valid\n",
        "    #     best_param = model.state_dict()\n",
        "    #     torch.save(best_param, MODEL_DIR+f'best_param.pt')\n",
        "    #     patience = 0\n",
        "    # else:\n",
        "    #     patience += 1\n",
        "    #     if patience >= 3:\n",
        "    #         del train_loader, valid_loader, loss_train, out_valid\n",
        "    #         torch.cuda.empty_cache()\n",
        "    #         gc.collect()\n",
        "    #         break\n",
        "\n",
        "    del train_loader, loss_train, \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4eb3df024534187bdc1d7f4d91075ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/78 [00:01<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-1a43a85611e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=EPOCHS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, scheduler)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# out_valid = test_model(valid_loader, model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-9ab29ff2c669>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, model, optimizer, criterion)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# score = roc_auc_score(labels.detach().cpu().numpy(), out[:,1].detach().cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_metric_learning/losses/base_metric_loss_function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, labels, indices_tuple)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_embedding_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_norms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_metric_learning/losses/triplet_margin_loss.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, embeddings, labels, indices_tuple)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mindices_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_per_anchor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriplets_per_anchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0manchor_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_metric_learning/utils/loss_and_miner_utils.py\u001b[0m in \u001b[0;36mconvert_to_triplets\u001b[0;34m(indices_tuple, labels, t_per_anchor)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindices_tuple\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_per_anchor\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_all_triplets_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_random_triplet_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_per_anchor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_per_anchor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_metric_learning/utils/loss_and_miner_utils.py\u001b[0m in \u001b[0;36mget_all_triplets_indices\u001b[0;34m(labels, ref_labels)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mtriplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdiffs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0ma_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mp_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mn_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 10.12 GiB (GPU 0; 11.17 GiB total capacity; 7.88 GiB already allocated; 2.83 GiB free; 7.97 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yFQxlZT--VyT"
      },
      "source": [
        "## 学習モデルを用いて提出ファイル作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VD34AvNo_L8H",
        "colab": {}
      },
      "source": [
        "model = KDDModel().to(device)\n",
        "model.load_state_dict(torch.load(MODEL_DIR+f'best_param.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf66LPuDNxUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Mutiple GPU使った場合\n",
        "\n",
        "# def fix_model_state_dict(state_dict):\n",
        "#     new_state_dict = OrderedDict()\n",
        "#     for k, v in state_dict.items():\n",
        "#         name = k\n",
        "#         if name.startswith('module.'):\n",
        "#             name = name[7:]  # remove 'module.' of dataparallel\n",
        "#         new_state_dict[name] = v\n",
        "#     return new_state_dict\n",
        "\n",
        "# model = KDDModel().to(device)\n",
        "# model.load_state_dict(fix_model_state_dict(torch.load(MODEL_DIR+f'best_param.pt')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nGVfkoEf_Lpd",
        "colab": {}
      },
      "source": [
        "def make_submit_df(df_test, model):\n",
        "    dataset_test = KDDDataset(df_test, train_mode=False)\n",
        "    test_loader = DataLoader(dataset_test, batch_size=128, shuffle=False, num_workers=0, drop_last=False)\n",
        "    out_list = test_model(test_loader, model)\n",
        "\n",
        "    for i, out in enumerate(out_list):\n",
        "        if i==0:\n",
        "            out_array = out.squeeze()\n",
        "        else:\n",
        "            out_array = torch.cat([out_array, out.squeeze()], dim=-1)\n",
        "\n",
        "    out_array = out_array.cpu().detach().numpy()\n",
        "    df_test['score'] = out_array\n",
        "    \n",
        "    # sort and group by\n",
        "    df_test = df_test.sort_values(by=\"score\", ascending=False)\n",
        "    grouped = df_test.groupby(\"query_id\").head(5)\n",
        "    \n",
        "    submit_df = pd.DataFrame(columns=['query-id','product1','product2','product3','product4','product5'])\n",
        "    for i, q_id in enumerate(tqdm(grouped['query_id'].unique())):\n",
        "        submit_df.loc[i, 'query-id'] = q_id\n",
        "        submit_df.iloc[i, 1:] = grouped.loc[(grouped['query_id']==q_id), 'product_id'].values\n",
        "    submit_df = submit_df.astype(int)\n",
        "    submit_df = submit_df.sort_values(by='query-id')\n",
        "    submit_df = submit_df.reset_index(drop=True)\n",
        "    \n",
        "    return submit_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0JiU01lb_LZ7",
        "colab": {}
      },
      "source": [
        "submit_df = make_submit_df(testA, model)\n",
        "submit_df.to_csv(SUBMIT_DIR+'submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wSrMWqt4B_Ez",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}