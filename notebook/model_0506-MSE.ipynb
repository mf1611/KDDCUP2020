{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import logging\n",
    "import json\n",
    "\n",
    "import base64\n",
    "import swifter\n",
    "import gensim\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "#import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using backend: pytorch\n",
      "ERROR:root:The testing module requires faiss. You can install the GPU version with the command 'conda install faiss-gpu -c pytorch' \n",
      "                        or the CPU version with 'conda install faiss-cpu -c pytorch'. Learn more at https://github.com/facebookresearch/faiss/blob/master/INSTALL.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import networkx as nx\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
    "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
    "    get_cosine_schedule_with_warmup,DistilBertTokenizer,DistilBertModel\n",
    ")\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/m_fujitsuka/mnt/data/'\n",
    "FEATURE_DIR = '/home/m_fujitsuka/mnt/fujitsuka/features/'\n",
    "LOG_DIR = '/home/m_fujitsuka/mnt/fujitsuka/log/'\n",
    "W2V_DIR = '/home/m_fujitsuka/mnt/fujitsuka/w2v/'\n",
    "MODEL_DIR = '/home/m_fujitsuka/mnt/fujitsuka/model/'\n",
    "SUBMIT_DIR = '/home/m_fujitsuka/mnt/fujitsuka/prediction_result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(FEATURE_DIR+'train.pkl')\n",
    "valid = pd.read_pickle(FEATURE_DIR+'valid.pkl')\n",
    "testA = pd.read_pickle(FEATURE_DIR+'testA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>image_h</th>\n",
       "      <th>image_w</th>\n",
       "      <th>num_boxes</th>\n",
       "      <th>boxes</th>\n",
       "      <th>features</th>\n",
       "      <th>class_labels</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>box_area_normalized</th>\n",
       "      <th>class_labels_vec</th>\n",
       "      <th>center_normalized</th>\n",
       "      <th>adj_mat</th>\n",
       "      <th>box_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102851856</td>\n",
       "      <td>338</td>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "      <td>[[0.0, 3.0, 338.0, 207.0], [239.0, 22.0, 333.0...</td>\n",
       "      <td>[[0.0, 0.0, 6.0378604, 0.0, 0.037252333, 0.0, ...</td>\n",
       "      <td>others others</td>\n",
       "      <td>treble popular reed</td>\n",
       "      <td>923271</td>\n",
       "      <td>[0.9760765550239234, 0.2421788737578212]</td>\n",
       "      <td>[-0.16868001, -0.257395, -0.53158, -0.04389, -...</td>\n",
       "      <td>[[0.5023923444976076, 0.5], [0.540669856459330...</td>\n",
       "      <td>[[0.0, 2.7414992979958495], [2.741499297995849...</td>\n",
       "      <td>[[0.0, 0.014354066985645933, 1.0, 0.9904306220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101783080</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>[[5.0, 5.0, 75.0, 56.0]]</td>\n",
       "      <td>[[0.0, 0.015551143, 1.4977295, 0.0, 0.03303502...</td>\n",
       "      <td>others</td>\n",
       "      <td>compatible ink cartridges</td>\n",
       "      <td>234031</td>\n",
       "      <td>[0.7315573770491803]</td>\n",
       "      <td>[-0.16868001, -0.257395, -0.53158, -0.04389, -...</td>\n",
       "      <td>[[0.5, 0.5]]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>[[0.0625, 0.08196721311475409, 0.9375, 0.91803...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100492797</td>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>1</td>\n",
       "      <td>[[43.0, 263.0, 658.0, 468.0]]</td>\n",
       "      <td>[[0.0, 0.0, 0.81766355, 0.0, 0.02573972, 0.0, ...</td>\n",
       "      <td>makeup, perfume, beauty tools and essential oils</td>\n",
       "      <td>check new look facial cream</td>\n",
       "      <td>199926</td>\n",
       "      <td>[0.2241333333333333]</td>\n",
       "      <td>[-0.122048564, 0.036015432, -0.06529144, 0.100...</td>\n",
       "      <td>[[0.48733333333333334, 0.4673333333333333]]</td>\n",
       "      <td>[[0.0]]</td>\n",
       "      <td>[[0.05733333333333333, 0.3506666666666667, 0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101708088</td>\n",
       "      <td>480</td>\n",
       "      <td>640</td>\n",
       "      <td>5</td>\n",
       "      <td>[[250.0, 421.0, 416.0, 635.0], [252.0, 5.0, 42...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.24994667, 0.0, 0.0, 0....</td>\n",
       "      <td>others others others others others</td>\n",
       "      <td>royal commemorative stamp</td>\n",
       "      <td>772725</td>\n",
       "      <td>[0.11563802083333333, 0.120419921875, 0.133255...</td>\n",
       "      <td>[-0.16868001, -0.257395, -0.53158, -0.04389, -...</td>\n",
       "      <td>[[0.825, 0.6937500000000001], [0.17109375, 0.7...</td>\n",
       "      <td>[[0.0, 82.60384316863635, 50.596186563989285, ...</td>\n",
       "      <td>[[0.5208333333333334, 0.6578125, 0.86666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100316842</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>[[138.0, 257.0, 716.0, 540.0], [162.0, 667.0, ...</td>\n",
       "      <td>[[0.0, 0.014258672, 0.02542738, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>others snacks, nuts, liquor and tea snacks, nu...</td>\n",
       "      <td>calendula baby shower gel</td>\n",
       "      <td>362576</td>\n",
       "      <td>[0.25558437500000003, 0.0356, 0.03279375, 0.21...</td>\n",
       "      <td>[-0.03929567, -0.14148633, -0.143134, -0.30245...</td>\n",
       "      <td>[[0.49812500000000004, 0.53375], [0.9137500000...</td>\n",
       "      <td>[[0.0, 3.7297644696196075, 3.456343151840976, ...</td>\n",
       "      <td>[[0.1725, 0.32125, 0.895, 0.675], [0.2025, 0.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  image_h  image_w  num_boxes  \\\n",
       "0   102851856      338      209          2   \n",
       "1   101783080       80       61          1   \n",
       "2   100492797      750      750          1   \n",
       "3   101708088      480      640          5   \n",
       "4   100316842      800      800          4   \n",
       "\n",
       "                                               boxes  \\\n",
       "0  [[0.0, 3.0, 338.0, 207.0], [239.0, 22.0, 333.0...   \n",
       "1                           [[5.0, 5.0, 75.0, 56.0]]   \n",
       "2                      [[43.0, 263.0, 658.0, 468.0]]   \n",
       "3  [[250.0, 421.0, 416.0, 635.0], [252.0, 5.0, 42...   \n",
       "4  [[138.0, 257.0, 716.0, 540.0], [162.0, 667.0, ...   \n",
       "\n",
       "                                            features  \\\n",
       "0  [[0.0, 0.0, 6.0378604, 0.0, 0.037252333, 0.0, ...   \n",
       "1  [[0.0, 0.015551143, 1.4977295, 0.0, 0.03303502...   \n",
       "2  [[0.0, 0.0, 0.81766355, 0.0, 0.02573972, 0.0, ...   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.24994667, 0.0, 0.0, 0....   \n",
       "4  [[0.0, 0.014258672, 0.02542738, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                        class_labels  \\\n",
       "0                                      others others   \n",
       "1                                             others   \n",
       "2   makeup, perfume, beauty tools and essential oils   \n",
       "3                 others others others others others   \n",
       "4  others snacks, nuts, liquor and tea snacks, nu...   \n",
       "\n",
       "                         query  query_id  \\\n",
       "0          treble popular reed    923271   \n",
       "1    compatible ink cartridges    234031   \n",
       "2  check new look facial cream    199926   \n",
       "3    royal commemorative stamp    772725   \n",
       "4    calendula baby shower gel    362576   \n",
       "\n",
       "                                 box_area_normalized  \\\n",
       "0           [0.9760765550239234, 0.2421788737578212]   \n",
       "1                               [0.7315573770491803]   \n",
       "2                               [0.2241333333333333]   \n",
       "3  [0.11563802083333333, 0.120419921875, 0.133255...   \n",
       "4  [0.25558437500000003, 0.0356, 0.03279375, 0.21...   \n",
       "\n",
       "                                    class_labels_vec  \\\n",
       "0  [-0.16868001, -0.257395, -0.53158, -0.04389, -...   \n",
       "1  [-0.16868001, -0.257395, -0.53158, -0.04389, -...   \n",
       "2  [-0.122048564, 0.036015432, -0.06529144, 0.100...   \n",
       "3  [-0.16868001, -0.257395, -0.53158, -0.04389, -...   \n",
       "4  [-0.03929567, -0.14148633, -0.143134, -0.30245...   \n",
       "\n",
       "                                   center_normalized  \\\n",
       "0  [[0.5023923444976076, 0.5], [0.540669856459330...   \n",
       "1                                       [[0.5, 0.5]]   \n",
       "2        [[0.48733333333333334, 0.4673333333333333]]   \n",
       "3  [[0.825, 0.6937500000000001], [0.17109375, 0.7...   \n",
       "4  [[0.49812500000000004, 0.53375], [0.9137500000...   \n",
       "\n",
       "                                             adj_mat  \\\n",
       "0  [[0.0, 2.7414992979958495], [2.741499297995849...   \n",
       "1                                            [[0.0]]   \n",
       "2                                            [[0.0]]   \n",
       "3  [[0.0, 82.60384316863635, 50.596186563989285, ...   \n",
       "4  [[0.0, 3.7297644696196075, 3.456343151840976, ...   \n",
       "\n",
       "                                      box_normalized  \n",
       "0  [[0.0, 0.014354066985645933, 1.0, 0.9904306220...  \n",
       "1  [[0.0625, 0.08196721311475409, 0.9375, 0.91803...  \n",
       "2  [[0.05733333333333333, 0.3506666666666667, 0.8...  \n",
       "3  [[0.5208333333333334, 0.6578125, 0.86666666666...  \n",
       "4  [[0.1725, 0.32125, 0.895, 0.675], [0.2025, 0.8...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Sample作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200000, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 今回は、まず4割で！！\n",
    "train = train.sample(frac=0.4, random_state=42)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['label'] = 1\n",
    "\n",
    "# random.seed(42)\n",
    "# ind = list(train.index)\n",
    "# random.shuffle(ind)\n",
    "\n",
    "# train_neg = train.copy(deep=True)\n",
    "# train_neg['label'] = 0\n",
    "# train_neg['query'] = list(train_neg['query'].loc[ind])[:]\n",
    "# train_neg.head()\n",
    "\n",
    "# train = pd.concat([train, train_neg], axis=0)\n",
    "# train = train.reset_index(drop=True)\n",
    "# print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('main')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "sc = logging.StreamHandler()\n",
    "logger.addHandler(sc)\n",
    "fh = logging.FileHandler(LOG_DIR+'20200506_each.log')\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 20\n",
    "\n",
    "class KDDDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, train_mode=True, transform=None):\n",
    "        self.df = df\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        #self.w2v_tokenizer = tokenizer_w2v\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        ######################\n",
    "        # query side\n",
    "        ######################\n",
    "        query = row['query']\n",
    "        inputs_query = self.bert_tokenizer.encode_plus(\n",
    "            query,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "        )\n",
    "        \n",
    "        ids_query = inputs_query[\"input_ids\"]\n",
    "        token_type_ids_query = inputs_query[\"token_type_ids\"]\n",
    "        mask_query = inputs_query[\"attention_mask\"]\n",
    "        \n",
    "        padding_len = MAX_LEN - len(ids_query)\n",
    "        ids_query = ids_query + ([0]*padding_len)\n",
    "        token_type_ids_query = token_type_ids_query + ([0]*padding_len)\n",
    "        mask_query = mask_query + ([0]*padding_len)\n",
    "        \n",
    "        \n",
    "        ######################\n",
    "        # image side\n",
    "        ######################\n",
    "        # box_areaの大きい順にソート\n",
    "        box_order = np.argsort(row.box_area_normalized)[::-1]\n",
    "\n",
    "        faetures_ordered = row.features[box_order, :]\n",
    "        box_ordered = row.box_normalized[box_order, :]\n",
    "        center_ordered = row.center_normalized[box_order, :]\n",
    "        area_ordered = row.box_area_normalized[box_order]\n",
    "\n",
    "        n_box = row.num_boxes\n",
    "        adj_mat = np.zeros((n_box, n_box))\n",
    "        if n_box!=1:\n",
    "            X = center_ordered[:,0]\n",
    "            Y = center_ordered[:,1]\n",
    "            for i in range(1, n_box):\n",
    "                d = np.sqrt((X[0] - X[i])**2 + (Y[0] - Y[i])**2)\n",
    "                adj_mat[0, i] = 1/d\n",
    "                adj_mat[i, 0] = 1/d\n",
    "\n",
    "        # adj_mat = row['adj_mat']\n",
    "        # features = row['features']\n",
    "        # box = row['box_normalized']\n",
    "        # box_area = row['box_area_normalized']\n",
    "        \n",
    "        nxg = nx.from_numpy_matrix(adj_mat)\n",
    "        g = dgl.DGLGraph()\n",
    "        g.from_networkx(nxg)\n",
    "        g.edata['weight'] = torch.tensor(nx.adjacency_matrix(nxg).data, dtype=torch.float).to(device)\n",
    "        g.ndata['h'] = torch.cat([torch.tensor(faetures_ordered, dtype=torch.float),torch.tensor(box_ordered, dtype=torch.float),torch.tensor(area_ordered.reshape(-1,1), dtype=torch.float)], dim=-1).to(device)\n",
    "        g.ndata['w'] = torch.tensor(area_ordered, dtype=torch.float).to(device)\n",
    "        \n",
    "        # class_labels\n",
    "        #class_labels_vec = row['class_labels_vec']  # 含めると悪化\n",
    "        \n",
    "        \n",
    "        if self.train_mode:\n",
    "            # positive, negative label\n",
    "            #labels = row['label']\n",
    "            \n",
    "            \n",
    "            return g, {\n",
    "                'ids_query': torch.tensor(ids_query, dtype=torch.long),\n",
    "                'mask_query': torch.tensor(mask_query, dtype=torch.long),\n",
    "                'token_type_ids_query': torch.tensor(token_type_ids_query, dtype=torch.long),\n",
    "                #'class_labels_vec': torch.tensor(class_labels_vec, dtype=torch.float),\n",
    "                #'label': torch.tensor(labels, dtype=torch.float),\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            return g, {\n",
    "                'ids_query': torch.tensor(ids_query, dtype=torch.long),\n",
    "                'mask_query': torch.tensor(mask_query, dtype=torch.long),\n",
    "                'token_type_ids_query': torch.tensor(token_type_ids_query, dtype=torch.long),\n",
    "                #'class_labels_vec': torch.tensor(class_labels_vec, dtype=torch.float),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    # input samples は、ペアのリスト\n",
    "    #  [(graph, {features}),...], バッチサイズの長さのリスト\n",
    "    # グラフは、隣接行列を対角につなげて1つのバッチにする\n",
    "    # 他のfeatureは、(バッチサイズ, 次元数)のtensor\n",
    "    \n",
    "    graphs, features_dict = map(list, zip(*samples))\n",
    "    \n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    \n",
    "    batched_features = {}\n",
    "    labels = []\n",
    "    for i, feat in enumerate(features_dict):\n",
    "        if i==0:\n",
    "            for (key, val) in feat.items():\n",
    "                batched_features[key] = val.view(1,-1)\n",
    "               \n",
    "        else:\n",
    "            for (key, val) in feat.items():\n",
    "                batched_features[key] = torch.cat([batched_features[key],  val.view(1,-1)], dim=0)\n",
    "                    \n",
    "    return batched_graph, batched_features\n",
    "\n",
    "\n",
    "def collate_test(samples):\n",
    "    # input samples は、ペアのリスト\n",
    "    #  [(graph, {features}),...], バッチサイズの長さのリスト\n",
    "    # グラフは、隣接行列を対角につなげて1つのバッチにする\n",
    "    # 他のfeatureは、(バッチサイズ, 次元数)のtensor\n",
    "    \n",
    "    graphs, features_dict = map(list, zip(*samples))\n",
    "    \n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    \n",
    "    batched_features = {}\n",
    "    labels = []\n",
    "    for i, feat in enumerate(features_dict):\n",
    "        if i==0:\n",
    "            for (key, val) in feat.items():\n",
    "                batched_features[key] = val.view(1,-1)\n",
    "        else:\n",
    "            for (key, val) in feat.items():\n",
    "                batched_features[key] = torch.cat([batched_features[key],  val.view(1,-1)], dim=0)\n",
    "        \n",
    "    return batched_graph, batched_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dataloaderの挙動確認\n",
    "\n",
    "# dataset_train = KDDDataset(train, train_mode=True)\n",
    "# train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0, drop_last=True, collate_fn=collate)\n",
    "\n",
    "# for i, (graph, features) in enumerate(train_loader):\n",
    "#     if i<1:\n",
    "#         print(graph.batch_size)\n",
    "#         print(graph)\n",
    "#         print(features['ids_query'].shape)\n",
    "#         print(features['mask_query'].shape)\n",
    "#         print(features['token_type_ids_query'].shape)\n",
    "#         print(features['class_labels_vec'].shape)\n",
    "#         print(features['label'].shape)\n",
    "\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.fc = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        \"\"\"edgeを通して，どのようなメッセージをどう渡すかを決める関数\"\"\"\n",
    "        weight = edges.data['weight'].view(-1, 1)\n",
    "        messages = edges.src['h'] * weight\n",
    "        return {'m': messages}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        \"\"\"渡されたメッセージをどのように集約するかを決める関数\"\"\"\n",
    "        messages = nodes.mailbox['m']\n",
    "        h = torch.sum(messages, dim=1)\n",
    "        return {'h': h}\n",
    "    \n",
    "    def node_apply_func(self, nodes):\n",
    "        \"\"\"ノードごとに作用させる関数\"\"\"\n",
    "        h = self.fc(nodes.data['h'])\n",
    "        h = self.activation(h)\n",
    "        return {'h': h}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        g.ndata['h'] = h\n",
    "        g.apply_nodes(self.node_apply_func)\n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "        return g.ndata.pop('h')  # ndata['h']が削除されるが，返り値としては，ndata['h']となる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QueryModel, self).__init__()\n",
    "        self.model_name = 'QueryModel'\n",
    "\n",
    "        # query\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.fc_bert = nn.Linear(768, 128)\n",
    "        #self.fc_bert2 = nn.Linear(128, 64)\n",
    "\n",
    "\n",
    "    def forward(self, ids, token_type_ids, mask):\n",
    "        \n",
    "        ##############################\n",
    "        # query\n",
    "        ##############################\n",
    "        layers, pool_out = self.bert_model(input_ids=ids, token_type_ids=token_type_ids, attention_mask=mask)\n",
    "        out_query = F.avg_pool1d(layers.transpose(1,2), kernel_size=layers.size()[1]).squeeze()\n",
    "        out_query = F.dropout(out_query, p=0.3, training=self.training)\n",
    "        out_query = F.relu(self.fc_bert(out_query))\n",
    "        #out_query = F.relu(self.fc_bert2(out_query))\n",
    "        \n",
    "        return out_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.model_name = 'ImageModel'\n",
    "\n",
    "        # image\n",
    "        self.gcn1 = GCN(2048+4+1, 512, F.relu)\n",
    "        self.gcn2 = GCN(512, 256, F.relu)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        #self.fc2 = nn.Linear(128, 64)\n",
    "\n",
    "\n",
    "    def forward(self, g):\n",
    "        \n",
    "        ##############################\n",
    "        # image\n",
    "        ##############################\n",
    "        h = g.ndata.pop('h')\n",
    "        h = self.gcn1(g, h)\n",
    "        h = self.gcn2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        \n",
    "        for i, graph in enumerate(dgl.unbatch(g)):\n",
    "            if i==0:\n",
    "                out_image = graph.ndata['h'][0].unsqueeze(0)\n",
    "            else:\n",
    "                out_image = torch.cat([out_image, graph.ndata['h'][0].unsqueeze(0)], dim=0)\n",
    "\n",
    "\n",
    "        # Calculate graph representation by averaging all the node representations.\n",
    "        #out_image = dgl.mean_nodes(g, 'h', 'w')  # wでの重み付き平均\n",
    "        # out_image = dgl.max_nodes(g, 'h')\n",
    "        \n",
    "        #out_image = torch.cat([out_image, class_labels_vec], dim=-1)\n",
    "        \n",
    "        out_image = F.dropout(out_image, p=0.2, training=self.training)\n",
    "        out_image = F.relu(self.fc1(out_image))\n",
    "        #out_image = F.relu(self.fc2(out_image))\n",
    "        \n",
    "        return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDDModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KDDModel, self).__init__()\n",
    "        self.model_name = 'KDDModel'\n",
    "\n",
    "        self.model_query = QueryModel()\n",
    "        self.model_image = ImageModel()\n",
    "\n",
    "\n",
    "    def forward(self, ids, token_type_ids, mask, g):\n",
    "        \n",
    "        out_query = self.model_query(ids, token_type_ids, mask)\n",
    "        out_image = self.model_image(g)\n",
    "        \n",
    "        return out_query, out_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, model, optimizer, criterion): #, scheduler):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    avg_score = 0.\n",
    "    for idx, (graph, features) in enumerate(tqdm(train_loader)):\n",
    "        ids_query = features['ids_query'].to(device)\n",
    "        mask_query = features['mask_query'].to(device)\n",
    "        token_type_ids_query = features['token_type_ids_query'].to(device)\n",
    "        #labels = features['label'].to(device)\n",
    "\n",
    "        out_query, out_image = model(ids_query, token_type_ids_query, mask_query, graph)\n",
    "        \n",
    "        loss = criterion(out_query, out_image)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        del ids_query,mask_query,token_type_ids_query,out_query,out_image,loss\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "def test_model(test_loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    out_list = []   \n",
    "    with torch.no_grad():\n",
    "        for idx, (graph, features) in enumerate(tqdm(test_loader)):\n",
    "            ids_query = features['ids_query'].to(device)\n",
    "            mask_query = features['mask_query'].to(device)\n",
    "            token_type_ids_query = features['token_type_ids_query'].to(device)\n",
    "\n",
    "            out_query, out_image = model(ids_query, token_type_ids_query, mask_query, graph)\n",
    "\n",
    "            out = F.cosine_similarity(out_query, out_image)\n",
    "\n",
    "            out_list.append(out)\n",
    "            del ids_query,mask_query,token_type_ids_query,out_query,out_image\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(train_loader, model, optimizer, criterion): #, scheduler):\n",
    "#     model.train()\n",
    "#     avg_loss = 0.\n",
    "#     avg_score = 0.\n",
    "#     for idx, (graph, features) in enumerate(tqdm(train_loader)):\n",
    "#         ids_query = features['ids_query'].to(device)\n",
    "#         mask_query = features['mask_query'].to(device)\n",
    "#         token_type_ids_query = features['token_type_ids_query'].to(device)\n",
    "#         labels = features['label'].to(device)\n",
    "\n",
    "#         out = model(ids_query, token_type_ids_query, mask_query, graph)\n",
    "        \n",
    "#         loss = criterion(out, labels)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "#         del ids_query,mask_query,token_type_ids_query,labels,out,loss\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "#     return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "# def test_model(test_loader, model):\n",
    "#     model.eval()\n",
    "    \n",
    "#     out_list = []   \n",
    "#     with torch.no_grad():\n",
    "#         for idx, (graph, features) in enumerate(tqdm(test_loader)):\n",
    "#             ids_query = features['ids_query'].to(device)\n",
    "#             mask_query = features['mask_query'].to(device)\n",
    "#             token_type_ids_query = features['token_type_ids_query'].to(device)\n",
    "\n",
    "#             out_query = model.model_query(ids_query, token_type_ids_query, mask_query)\n",
    "#             out_image = model.model_image(graph)\n",
    "#             out = F.cosine_similarity(out_query, out_image)\n",
    "\n",
    "#             out_list.append(out)\n",
    "#             del ids_query,mask_query,token_type_ids_query,out\n",
    "        \n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "#     return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute dcg@k for a single sample\n",
    "def dcg_at_k(r, k):\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(3, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "\n",
    "# compute ndcg@k (dcg@k / idcg@k) for a single sample\n",
    "def get_ndcg(r, ref, k):\n",
    "    dcg_max = dcg_at_k(ref, k)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    dcg = dcg_at_k(r, k)\n",
    "    return dcg / dcg_max\n",
    "\n",
    "\n",
    "def make_score(df_test, out_list):\n",
    "    for i, out in enumerate(out_list):\n",
    "        if i==0:\n",
    "            out_array = out.squeeze()\n",
    "        else:\n",
    "            out_array = torch.cat([out_array, out.squeeze()], dim=-1)\n",
    "\n",
    "    out_array = out_array.cpu().detach().numpy()\n",
    "    df_test['score'] = out_array\n",
    "    \n",
    "    # sort and group by\n",
    "    df_test = df_test.sort_values(by=\"score\", ascending=False)\n",
    "    grouped = df_test.groupby(\"query_id\").head(5)\n",
    "    \n",
    "    predictions = {}\n",
    "    for i, q_id in enumerate(tqdm(grouped['query_id'].unique())):\n",
    "        predictions[f'{q_id}'] = grouped.loc[(grouped['query_id']==q_id), 'product_id'].values.astype(str)\n",
    "    \n",
    "    \n",
    "    # read ground-truth\n",
    "    reference = json.load(open(DATA_DIR+'valid_answer.json'))\n",
    "\n",
    "    # compute score for each query\n",
    "    k = 5\n",
    "    score_sum = 0.\n",
    "    for qid in reference.keys():\n",
    "        ground_truth_ids = set([str(pid) for pid in reference[qid]])\n",
    "        ref_vec = [1.0] * len(ground_truth_ids)\n",
    "        pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions[qid]]\n",
    "        score_sum += get_ndcg(pred_vec, ref_vec, k)\n",
    "    # the higher score, the better\n",
    "    score = score_sum / len(reference)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88c32c7659f44aeafe57168d86880ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4687.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = KDDModel().to(device)\n",
    "\n",
    "# if device == 'cuda':\n",
    "#     model = torch.nn.DataParallel(model) # make parallel\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                         {'params': model.model_query.parameters()},\n",
    "#                         {'params': model.model_image.parameters()}\n",
    "#                     ])\n",
    "\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#criterion = nn.CosineSimilarity()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.CosineEmbeddingLoss()\n",
    "#criterion = losses.TripletMarginLoss(margin=0.1)\n",
    "\n",
    "loss_list_epoch_train = []\n",
    "score_list_epoch_valid = []\n",
    "score_best = 0\n",
    "patience = 0\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time   = time.time()\n",
    "\n",
    "    dataset_train = KDDDataset(train, train_mode=True)\n",
    "    dataset_valid = KDDDataset(valid, train_mode=False)\n",
    "    train_loader = DataLoader(dataset_train, batch_size=256, shuffle=True, num_workers=0, drop_last=True, collate_fn=collate)\n",
    "    valid_loader = DataLoader(dataset_valid, batch_size=256, shuffle=False, num_workers=0, drop_last=False, collate_fn=collate_test)\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "\n",
    "    loss_train = train_model(train_loader, model, optimizer, criterion) #, scheduler)\n",
    "    #scheduler.step()\n",
    "    out_valid = test_model(valid_loader, model)\n",
    "    score_valid = make_score(valid, out_valid)\n",
    "\n",
    "    loss_list_epoch_train.append(loss_train)\n",
    "    score_list_epoch_valid.append(score_valid)\n",
    "\n",
    "    logger.info(f'Epoch {(epoch+1)}, train_loss: {loss_train}, valid_score: {score_valid}, time: {(time.time()-start_time)}')\n",
    "\n",
    "    # Eearly Stopping\n",
    "    if score_valid > score_best:\n",
    "        score_best = score_valid\n",
    "        best_param = model.state_dict()\n",
    "        torch.save(best_param, MODEL_DIR+f'best_param.pt')\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience > 2:\n",
    "            del train_loader, valid_loader, loss_train, out_valid\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            break\n",
    "\n",
    "    del train_loader, valid_loader, loss_train, out_valid\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KDDModel().to(device)\n",
    "\n",
    "# # if device == 'cuda':\n",
    "# #     model = torch.nn.DataParallel(model) # make parallel\n",
    "# #     cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# # optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# optimizer = torch.optim.Adam([\n",
    "#                         {'params': model.model_query.parameters()},\n",
    "#                         {'params': model.model_image.parameters()}\n",
    "#                     ])\n",
    "\n",
    "\n",
    "# #criterion = nn.BCEWithLogitsLoss()\n",
    "# #criterion = nn.CosineSimilarity()\n",
    "# #criterion = nn.CosineEmbeddingLoss()\n",
    "# criterion = losses.TripletMarginLoss(margin=0.1)\n",
    "\n",
    "# loss_list_epoch_train = []\n",
    "# score_list_epoch_valid = []\n",
    "# score_best = 0\n",
    "# patience = 0\n",
    "# EPOCHS = 10\n",
    "# for epoch in range(EPOCHS):\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "#     start_time   = time.time()\n",
    "\n",
    "#     dataset_train = KDDDataset(train, train_mode=True)\n",
    "#     dataset_valid = KDDDataset(valid, train_mode=False)\n",
    "#     train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0, drop_last=True, collate_fn=collate)\n",
    "#     valid_loader = DataLoader(dataset_valid, batch_size=128, shuffle=False, num_workers=0, drop_last=False, collate_fn=collate_test)\n",
    "#     #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "#     #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
    "\n",
    "#     loss_train = train_model(train_loader, model, optimizer, criterion) #, scheduler)\n",
    "#     #scheduler.step()\n",
    "#     out_valid = test_model(valid_loader, model)\n",
    "#     score_valid = make_score(valid, out_valid)\n",
    "\n",
    "#     loss_list_epoch_train.append(loss_train)\n",
    "#     score_list_epoch_valid.append(score_valid)\n",
    "\n",
    "#     logger.info(f'Epoch {(epoch+1)}, train_loss: {loss_train}, valid_score: {score_valid}, time: {(time.time()-start_time)}')\n",
    "\n",
    "#     # Eearly Stopping\n",
    "#     if score_valid > score_best:\n",
    "#         score_best = score_valid\n",
    "#         best_param = model.state_dict()\n",
    "#         torch.save(best_param, MODEL_DIR+f'best_param.pt')\n",
    "#         patience = 0\n",
    "#     else:\n",
    "#         patience += 1\n",
    "#         if patience > 2:\n",
    "#             del train_loader, valid_loader, loss_train, out_valid\n",
    "#             torch.cuda.empty_cache()\n",
    "#             gc.collect()\n",
    "#             break\n",
    "\n",
    "#     del train_loader, valid_loader, loss_train, out_valid\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KDDModel().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_DIR+f'best_param.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submit_df(df_test, model):\n",
    "    dataset_test = KDDDataset(df_test, train_mode=False)\n",
    "    test_loader = DataLoader(dataset_test, batch_size=256, shuffle=False, num_workers=0, drop_last=False, collate_fn=collate_test)\n",
    "    out_list = test_model(test_loader, model)\n",
    "\n",
    "    for i, out in enumerate(out_list):\n",
    "        if i==0:\n",
    "            out_array = out.squeeze()\n",
    "        else:\n",
    "            out_array = torch.cat([out_array, out.squeeze()], dim=-1)\n",
    "\n",
    "    out_array = out_array.cpu().detach().numpy()\n",
    "    df_test['score'] = out_array\n",
    "    \n",
    "    # sort and group by\n",
    "    df_test = df_test.sort_values(by=\"score\", ascending=False)\n",
    "    grouped = df_test.groupby(\"query_id\").head(5)\n",
    "    \n",
    "    submit_df = pd.DataFrame(columns=['query-id','product1','product2','product3','product4','product5'])\n",
    "    for i, q_id in enumerate(tqdm(grouped['query_id'].unique())):\n",
    "        submit_df.loc[i, 'query-id'] = q_id\n",
    "        submit_df.iloc[i, 1:] = grouped.loc[(grouped['query_id']==q_id), 'product_id'].values\n",
    "    submit_df = submit_df.astype(int)\n",
    "    submit_df = submit_df.sort_values(by='query-id')\n",
    "    submit_df = submit_df.reset_index(drop=True)\n",
    "    \n",
    "    return submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = make_submit_df(testA, model)\n",
    "submit_df.to_csv(SUBMIT_DIR+'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
