{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "1stModel_kddcup_v10_metric_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-HFI_iXRGXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_azqvH__RTc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install swifter\n",
        "!pip install dgl-cu100\n",
        "!pip install pytorch-metric-learning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2nQtsuaQ7sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "from glob import glob\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import pickle\n",
        "import logging\n",
        "import json\n",
        "\n",
        "import base64\n",
        "import swifter\n",
        "import gensim\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import lightgbm as lgb\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "#import japanize_matplotlib\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "pd.set_option('display.max_columns', 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS9idpUtQ7tB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import networkx as nx\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "from dgl.nn.pytorch import GraphConv\n",
        "\n",
        "from pytorch_metric_learning import losses\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
        "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
        "    get_cosine_schedule_with_warmup,DistilBertTokenizer,DistilBertModel\n",
        ")\n",
        "\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyPd7iBzE2Ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0raUpbyRM9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/data/'\n",
        "LOG_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/log/'\n",
        "W2V_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/w2v/'\n",
        "MODEL_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/model/'\n",
        "SUBMIT_DIR = '/content/drive/My Drive/Colab Notebooks/KDDCUP/prediction_result/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ul-ZgurQ7tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DATA_DIR = 'D:/project/ICF_AutoCapsule_disabled/kddcup2020/data/'\n",
        "# LOG_DIR = 'D:/project/ICF_AutoCapsule_disabled/kddcup2020/log/'\n",
        "# W2V_DIR = 'D:/project/ICF_AutoCapsule_disabled/kddcup2020/w2v/'\n",
        "# BERT_DIR = 'D:/project/ICF_AutoCapsule_disabled/BERT/'\n",
        "# MODEL_DIR = 'D:/project/ICF_AutoCapsule_disabled/kddcup2020/model/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKWPOtZ8Q7tw",
        "colab_type": "text"
      },
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsD8ScdkQ7tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(DATA_DIR+'train/train.sample.tsv', sep='\\t')\n",
        "print(train.shape)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZtQFPJ_Q7uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid = pd.read_csv(DATA_DIR+'valid/valid.tsv', sep='\\t')\n",
        "print(valid.shape)\n",
        "valid.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQuRGN4iQ7uU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testA = pd.read_csv(DATA_DIR+'testA/testA.tsv', sep='\\t')\n",
        "print(testA.shape)\n",
        "testA.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK0eNvPyQ7uk",
        "colab_type": "text"
      },
      "source": [
        "### Decode Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7xfGrBxQ7uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_boxes(df_row):\n",
        "    return np.frombuffer(base64.b64decode(df_row.boxes), dtype=np.float32).reshape(df_row.num_boxes, 4)\n",
        "\n",
        "def transform_features(df_row):\n",
        "    return np.frombuffer(base64.b64decode(df_row.features), dtype=np.float32).reshape(df_row.num_boxes, 2048)\n",
        "\n",
        "def transform_class_labels(df_row):\n",
        "    return np.frombuffer(base64.b64decode(df_row.class_labels), dtype=np.int64).reshape(df_row.num_boxes)\n",
        "\n",
        "def transform_df(df):\n",
        "    df.boxes = df.swifter.apply(transform_boxes, axis=1)\n",
        "    df.features = df.swifter.apply(transform_features, axis=1)\n",
        "    df.class_labels = df.swifter.apply(transform_class_labels, axis=1)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gShMk_awQ7vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = transform_df(train)\n",
        "valid = transform_df(valid)\n",
        "testA = transform_df(testA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqa8bxca8f7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdXGQ2cUQ7vS",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZzx7nadQ7vU",
        "colab_type": "text"
      },
      "source": [
        "- box area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTNq3GdLO_iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['box_normalized'] = train.swifter.apply(lambda x: np.array([[xi[0]/x.image_h,xi[1]/x.image_w,xi[2]/x.image_h,xi[3]/x.image_w] for xi in x.boxes]), axis=1)\n",
        "valid['box_normalized'] = valid.swifter.apply(lambda x: np.array([[xi[0]/x.image_h,xi[1]/x.image_w,xi[2]/x.image_h,xi[3]/x.image_w] for xi in x.boxes]), axis=1)\n",
        "testA['box_normalized'] = testA.swifter.apply(lambda x: np.array([[xi[0]/x.image_h,xi[1]/x.image_w,xi[2]/x.image_h,xi[3]/x.image_w] for xi in x.boxes]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFt_GaxGRvN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdRtu_5zQ7vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# box area\n",
        "train['box_area_normalized'] = train.box_normalized.apply(lambda x: np.array([(xi[3]-xi[1]) * (xi[2]-xi[0]) for xi in x]))\n",
        "valid['box_area_normalized'] = valid.box_normalized.apply(lambda x: np.array([(xi[3]-xi[1]) * (xi[2]-xi[0]) for xi in x]))\n",
        "testA['box_area_normalized'] = testA.box_normalized.apply(lambda x: np.array([(xi[3]-xi[1]) * (xi[2]-xi[0]) for xi in x]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEuathzJ9ecz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg5QdYu5Q7vj",
        "colab_type": "text"
      },
      "source": [
        "- word2vec of box labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqV6V3G0Q7vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_label_dict = {\n",
        "    0:'top clothes (coat, jacket, shirt, etc.)',\n",
        "    1:'skirt & dress',\n",
        "    2:'bottom clothes (trousers, pants, etc.)',\n",
        "    3:'luggage, leather goods',\n",
        "    4:'shoes',\n",
        "    5:'accessories (jewelry, clothing accessories, belts, hats, scarves, etc.)',\n",
        "    6:'snacks, nuts, liquor and tea',\n",
        "    7:'makeup, perfume, beauty tools and essential oils',\n",
        "    8:'bottle drink',\n",
        "    9:'furniture',\n",
        "    10:'stationery',\n",
        "    11:'household electrical appliances',\n",
        "    12:'home decoration',\n",
        "    13:'household fabric',\n",
        "    14:'kitchenware',\n",
        "    15:'home / personal cleaning tools',\n",
        "    16:'storage supplies',\n",
        "    17:'motorcycle, motorcycle accessories, vehicles, bicycle and riding equipment',\n",
        "    18:'outdoor product',\n",
        "    19:'lighting',\n",
        "    20:'toys',\n",
        "    21:'underwear',\n",
        "    22:'digital supplies',\n",
        "    23:'bed linens',\n",
        "    24:'baby products',\n",
        "    25:'personal care',\n",
        "    26:'sporting goods',\n",
        "    27:'clothes (accessories, baby clothing, etc.)',\n",
        "    28:'others',\n",
        "    29:'human face',\n",
        "    30:'arm',\n",
        "    31:'hair',\n",
        "    32:'hand',\n",
        "}\n",
        "\n",
        "train.class_labels = train.class_labels.swifter.apply(lambda x: (' ').join([class_label_dict[xi] for xi in x]))\n",
        "valid.class_labels = valid.class_labels.swifter.apply(lambda x: (' ').join([class_label_dict[xi] for xi in x]))\n",
        "testA.class_labels = testA.class_labels.swifter.apply(lambda x: (' ').join([class_label_dict[xi] for xi in x]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeTqja5iQ7v3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def load_embeddings(path):\n",
        "    with open(path, encoding='utf-8') as f:\n",
        "        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))\n",
        "\n",
        "def build_matrix(word_index, path):\n",
        "    embedding_index = load_embeddings(path)\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "    unknown_words = []\n",
        "    \n",
        "    for word, i in word_index.items():  # word_indexのwordに対応するembがあれば、embを代入する\n",
        "        try:\n",
        "            embedding_matrix[i] = embedding_index[word]\n",
        "        except KeyError:\n",
        "            unknown_words.append(word)\n",
        "    return embedding_matrix, unknown_words\n",
        "\n",
        "\n",
        "def load_word_embed(word_embed_glove=W2V_DIR+\"glove.840B.300d.txt\", \n",
        "                    word_embed_crawl=W2V_DIR+\"crawl-300d-2M.vec\",\n",
        "                    save_filename=W2V_DIR+\"word_embedding_matrix_testA\",\n",
        "                    word_index=None):\n",
        "    \n",
        "    # Tokneizerの学習\n",
        "    Tokenizer = keras.preprocessing.text.Tokenizer(filters='', lower=False)\n",
        "    Tokenizer.fit_on_texts(list(train['query'])+list(valid['query'])+list(testA['query'])\n",
        "                           +list(train['class_labels'])+list(valid['class_labels'])+list(testA['class_labels']))\n",
        "    \n",
        "    if os.path.exists(save_filename + \".npy\"):\n",
        "        embedding_matrix = np.load(save_filename + \".npy\").astype(\"float32\")\n",
        "    else:\n",
        "        \n",
        "        if word_index is None:\n",
        "            word_index = Tokenizer.word_index\n",
        "        \n",
        "        glove_matrix, unknown_words_glove = build_matrix(word_index, word_embed_glove)\n",
        "        print('n unknown words (glove): ', len(unknown_words_glove))\n",
        "        \n",
        "        crawl_matrix, unknown_words_crawl = build_matrix(word_index, word_embed_crawl)\n",
        "        print('n unknown words (crawl): ', len(unknown_words_crawl))\n",
        "        \n",
        "        embedding_matrix = crawl_matrix + glove_matrix  \n",
        "        np.save(save_filename, embedding_matrix)\n",
        "\n",
        "        del crawl_matrix\n",
        "        del glove_matrix\n",
        "        gc.collect()\n",
        "        \n",
        "    return embedding_matrix, Tokenizer\n",
        "\n",
        "\n",
        "def calc_mean_w2v(class_labels):\n",
        "    class_labels_index = tokenizer_w2v.texts_to_sequences([class_labels])\n",
        "    return np.mean(embedding_matrix[class_labels_index], axis=0)\n",
        "    \n",
        "    # try:\n",
        "    #     return embedding_matrix[class_labels_index]\n",
        "    #     #return np.mean(embedding_matrix[class_labels_index], axis=0)\n",
        "    # except KeyError:\n",
        "    #     print('Error')\n",
        "    #     return np.zeros(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlQvm9zjQ7wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# about 5 minites\n",
        "# embedding_matrix, tokenizer_w2v = load_word_embed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7CDChPYQ7wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train['class_labels_vec'] = train['class_labels'].swifter.apply(calc_mean_w2v)\n",
        "# valid['class_labels_vec'] = valid['class_labels'].swifter.apply(calc_mean_w2v)\n",
        "# testA['class_labels_vec'] = testA['class_labels'].swifter.apply(calc_mean_w2v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qd9-GX8Q7wh",
        "colab_type": "text"
      },
      "source": [
        "- Adjaccency matrix\n",
        "  - 面積が一番大きいboxを中心に、それと他の全ての結合グラフを考える"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLB-nPkCQ7wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from numba import jit\n",
        "\n",
        "# @jit\n",
        "# def get_adj_mat(X, Y, adj_mat):\n",
        "#     n_box = adj_mat.shape[0]\n",
        "#     if n_box!=1:\n",
        "#         for i in range(n_box):\n",
        "#             for j in range(i+1, n_box):\n",
        "#                 d = np.sqrt((X[i] - X[j])**2 + (Y[i] - Y[j])**2)\n",
        "#                 adj_mat[i, j] = 1/d\n",
        "#                 adj_mat[j, i] = 1/d\n",
        "                \n",
        "#     return adj_mat\n",
        "\n",
        "# def get_adj_mat_row(x):\n",
        "#     n_box = x.num_boxes\n",
        "#     adj_mat = np.zeros((n_box, n_box))\n",
        "#     return get_adj_mat(x.center_normalized[:,0], x.center_normalized[:,1], adj_mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70sFJ10cQ7wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # top/left/bottom/right\n",
        "# train['center_normalized'] = train.box_normalized.apply(lambda x: np.array([[((xi[3]-xi[1])/2+xi[1]), ((xi[2]-xi[0])/2+xi[0])] for xi in x]))\n",
        "# valid['center_normalized'] = valid.box_normalized.apply(lambda x: np.array([[((xi[3]-xi[1])/2+xi[1]), ((xi[2]-xi[0])/2+xi[0])] for xi in x]))\n",
        "# testA['center_normalized'] = testA.box_normalized.apply(lambda x: np.array([[((xi[3]-xi[1])/2+xi[1]), ((xi[2]-xi[0])/2+xi[0])] for xi in x]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCuJBahzFODo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq1SKNTaQ7xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train['adj_mat'] = train.swifter.apply(lambda x: get_adj_mat_row(x), axis=1)\n",
        "# valid['adj_mat'] = valid.swifter.apply(lambda x: get_adj_mat_row(x), axis=1)\n",
        "# testA['adj_mat'] = testA.swifter.apply(lambda x: get_adj_mat_row(x), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iduYj_1rGr3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGD91VIQ7xZ",
        "colab_type": "text"
      },
      "source": [
        "### Negative Sample生成\n",
        "- ここでは、簡単のため、queryだけランダムにシャッフルしたデータフレームを作成し、concatする\n",
        "- ラベルとして、元データはlabel=1, ランダムシャッフルはlabel=0とする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48lZ3h2Ukjyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['label'] = 1\n",
        "\n",
        "random.seed(42)\n",
        "ind = list(train.index)\n",
        "random.shuffle(ind)\n",
        "\n",
        "train_neg = train.copy(deep=True)\n",
        "train_neg['label'] = 0\n",
        "train_neg['query'] = list(train_neg['query'].loc[ind])[:]\n",
        "train_neg.head()\n",
        "\n",
        "train = pd.concat([train, train_neg], axis=0)\n",
        "train = train.reset_index(drop=True)\n",
        "print(train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGJ5UHpOkBYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2-gfgiHkEQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.iloc[10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAMB3K6TQ7xn",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHeB__sSQ7xp",
        "colab_type": "text"
      },
      "source": [
        "- initial setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuUmn9HBPT7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make logger\n",
        "logger = logging.getLogger('main')\n",
        "logger.setLevel(logging.DEBUG)\n",
        "sc = logging.StreamHandler()\n",
        "logger.addHandler(sc)\n",
        "fh = logging.FileHandler(LOG_DIR+'20200503_01.log')\n",
        "logger.addHandler(fh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx7jmHxZQ7xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8cHgIhXQ7x0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#device = 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubdQYpFeQ7x_",
        "colab_type": "text"
      },
      "source": [
        "### DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFjriqwvQ7yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 20\n",
        "\n",
        "class KDDDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, train_mode=True, transform=None):\n",
        "        self.df = df\n",
        "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.w2v_tokenizer = tokenizer_w2v\n",
        "        self.train_mode = train_mode\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        \n",
        "        ######################\n",
        "        # query side\n",
        "        ######################\n",
        "        query = row['query']\n",
        "        inputs_query = self.bert_tokenizer.encode_plus(\n",
        "            query,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "        )\n",
        "        \n",
        "        ids_query = inputs_query[\"input_ids\"]\n",
        "        token_type_ids_query = inputs_query[\"token_type_ids\"]\n",
        "        mask_query = inputs_query[\"attention_mask\"]\n",
        "        \n",
        "        padding_len = MAX_LEN - len(ids_query)\n",
        "        ids_query = ids_query + ([0]*padding_len)\n",
        "        token_type_ids_query = token_type_ids_query + ([0]*padding_len)\n",
        "        mask_query = mask_query + ([0]*padding_len)\n",
        "        \n",
        "        \n",
        "        ######################\n",
        "        # image side\n",
        "        ######################\n",
        "        # box_areaの大きい順にソート\n",
        "        box_order = np.argsort(row.box_area_normalized)[::-1]\n",
        "\n",
        "        faetures_ordered = row.features[box_order, :]\n",
        "        box_ordered = row.box_normalized[box_order, :]\n",
        "        area_ordered = row.box_area_normalized[box_order]\n",
        "\n",
        "        n_box = row.num_boxes\n",
        "        adj_mat = np.zeros((n_box, n_box))\n",
        "        if n_box!=1:\n",
        "            X = box_ordered[:,0]\n",
        "            Y = box_ordered[:,1]\n",
        "            for i in range(1, n_box):\n",
        "                d = np.sqrt((X[0] - X[i])**2 + (Y[0] - Y[i])**2)\n",
        "                adj_mat[0, i] = 1/d\n",
        "                adj_mat[i, 0] = 1/d\n",
        "\n",
        "        # adj_mat = row['adj_mat']\n",
        "        # features = row['features']\n",
        "        # box = row['box_normalized']\n",
        "        # box_area = row['box_area_normalized']\n",
        "        \n",
        "        nxg = nx.from_numpy_matrix(adj_mat)\n",
        "        g = dgl.DGLGraph()\n",
        "        g.from_networkx(nxg)\n",
        "        g.edata['weight'] = torch.tensor(nx.adjacency_matrix(nxg).data, dtype=torch.float).to(device)\n",
        "        g.ndata['h'] = torch.cat([torch.tensor(faetures_ordered, dtype=torch.float),torch.tensor(box_ordered, dtype=torch.float),torch.tensor(area_ordered.reshape(-1,1), dtype=torch.float)], dim=-1).to(device)\n",
        "        g.ndata['w'] = torch.tensor(area_ordered, dtype=torch.float).to(device)\n",
        "        \n",
        "        # class_labels\n",
        "        #class_labels_vec = row['class_labels_vec']\n",
        "        \n",
        "        \n",
        "        if self.train_mode:\n",
        "            # positive, negative label\n",
        "            labels = row['label']\n",
        "            \n",
        "            \n",
        "            return g, {\n",
        "                'ids_query': torch.tensor(ids_query, dtype=torch.long),\n",
        "                'mask_query': torch.tensor(mask_query, dtype=torch.long),\n",
        "                'token_type_ids_query': torch.tensor(token_type_ids_query, dtype=torch.long),\n",
        "                #'class_labels_vec': torch.tensor(class_labels_vec, dtype=torch.float),\n",
        "                'label': torch.tensor(labels, dtype=torch.float),\n",
        "            }\n",
        "        \n",
        "        else:\n",
        "            return g, {\n",
        "                'ids_query': torch.tensor(ids_query, dtype=torch.long),\n",
        "                'mask_query': torch.tensor(mask_query, dtype=torch.long),\n",
        "                'token_type_ids_query': torch.tensor(token_type_ids_query, dtype=torch.long),\n",
        "                #'class_labels_vec': torch.tensor(class_labels_vec, dtype=torch.float),\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWKHXRApQ7yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(samples):\n",
        "    # input samples は、ペアのリスト\n",
        "    #  [(graph, {features}),...], バッチサイズの長さのリスト\n",
        "    # グラフは、隣接行列を対角につなげて1つのバッチにする\n",
        "    # 他のfeatureは、(バッチサイズ, 次元数)のtensor\n",
        "    \n",
        "    graphs, features_dict = map(list, zip(*samples))\n",
        "    \n",
        "    batched_graph = dgl.batch(graphs)\n",
        "    \n",
        "    batched_features = {}\n",
        "    labels = []\n",
        "    for i, feat in enumerate(features_dict):\n",
        "        if i==0:\n",
        "            for (key, val) in feat.items():\n",
        "                if key!='label':\n",
        "                    batched_features[key] = val.view(1,-1)\n",
        "                else:\n",
        "                    labels.append(val.item())\n",
        "        else:\n",
        "            for (key, val) in feat.items():\n",
        "                if key!='label':\n",
        "                    batched_features[key] = torch.cat([batched_features[key],  val.view(1,-1)], dim=0)\n",
        "                else:\n",
        "                    labels.append(val.item())\n",
        "    \n",
        "    batched_features['label'] = torch.tensor(labels, dtype=torch.float)\n",
        "    \n",
        "    return batched_graph, batched_features\n",
        "\n",
        "\n",
        "def collate_test(samples):\n",
        "    # input samples は、ペアのリスト\n",
        "    #  [(graph, {features}),...], バッチサイズの長さのリスト\n",
        "    # グラフは、隣接行列を対角につなげて1つのバッチにする\n",
        "    # 他のfeatureは、(バッチサイズ, 次元数)のtensor\n",
        "    \n",
        "    graphs, features_dict = map(list, zip(*samples))\n",
        "    \n",
        "    batched_graph = dgl.batch(graphs)\n",
        "    \n",
        "    batched_features = {}\n",
        "    labels = []\n",
        "    for i, feat in enumerate(features_dict):\n",
        "        if i==0:\n",
        "            for (key, val) in feat.items():\n",
        "                if key!='label':\n",
        "                    batched_features[key] = val.view(1,-1)\n",
        "                else:\n",
        "                    labels.append(val.item())\n",
        "        else:\n",
        "            for (key, val) in feat.items():\n",
        "                if key!='label':\n",
        "                    batched_features[key] = torch.cat([batched_features[key],  val.view(1,-1)], dim=0)\n",
        "                else:\n",
        "                    labels.append(val.item())\n",
        "        \n",
        "    return batched_graph, batched_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xvkO9HhiQ7yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # dataloaderの挙動確認\n",
        "\n",
        "# dataset_train = KDDDataset(train, train_mode=True)\n",
        "# train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0, drop_last=True, collate_fn=collate)\n",
        "\n",
        "# for i, (graph, features) in enumerate(train_loader):\n",
        "#     if i<1:\n",
        "#         print(graph.batch_size)\n",
        "#         print(graph)\n",
        "#         print(features['ids_query'].shape)\n",
        "#         print(features['mask_query'].shape)\n",
        "#         print(features['token_type_ids_query'].shape)\n",
        "#         print(features['class_labels_vec'].shape)\n",
        "#         print(features['label'].shape)\n",
        "\n",
        "#     else:\n",
        "#         break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87pW9Hat2nBm",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKt5PpzZbq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, activation):\n",
        "        super(GCN, self).__init__()\n",
        "        self.fc = nn.Linear(in_feats, out_feats)\n",
        "        self.activation = activation\n",
        "    \n",
        "    def message_func(self, edges):\n",
        "        \"\"\"edgeを通して，どのようなメッセージをどう渡すかを決める関数\"\"\"\n",
        "        weight = edges.data['weight'].view(-1, 1)\n",
        "        messages = edges.src['h'] * weight\n",
        "        return {'m': messages}\n",
        "    \n",
        "    def reduce_func(self, nodes):\n",
        "        \"\"\"渡されたメッセージをどのように集約するかを決める関数\"\"\"\n",
        "        messages = nodes.mailbox['m']\n",
        "        h = torch.sum(messages, dim=1)\n",
        "        return {'h': h}\n",
        "    \n",
        "    def node_apply_func(self, nodes):\n",
        "        \"\"\"ノードごとに作用させる関数\"\"\"\n",
        "        h = self.fc(nodes.data['h'])\n",
        "        h = self.activation(h)\n",
        "        return {'h': h}\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        g.ndata['h'] = h\n",
        "        g.apply_nodes(self.node_apply_func)\n",
        "        g.update_all(self.message_func, self.reduce_func)\n",
        "        return g.ndata.pop('h')  # ndata['h']が削除されるが，返り値としては，ndata['h']となる"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbkqLzGMCvDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QueryModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QueryModel, self).__init__()\n",
        "        self.model_name = 'QueryModel'\n",
        "\n",
        "        # query\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.fc_bert = nn.Linear(768, 128)\n",
        "        self.fc_bert2 = nn.Linear(128, 64)\n",
        "\n",
        "\n",
        "    def forward(self, ids, token_type_ids, mask):\n",
        "        \n",
        "        ##############################\n",
        "        # query\n",
        "        ##############################\n",
        "        layers, pool_out = self.bert_model(input_ids=ids, token_type_ids=token_type_ids, attention_mask=mask)\n",
        "        out_query = F.avg_pool1d(layers.transpose(1,2), kernel_size=layers.size()[1]).squeeze()\n",
        "        out_query = F.dropout(out_query, p=0.3, training=self.training)\n",
        "        out_query = F.relu(self.fc_bert(out_query))\n",
        "        out_query = F.relu(self.fc_bert2(out_query))\n",
        "        \n",
        "        return out_query"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdpMq4eCv0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageModel, self).__init__()\n",
        "        self.model_name = 'ImageModel'\n",
        "\n",
        "        # image\n",
        "        self.gcn1 = GCN(2048+5, 512, F.relu)\n",
        "        self.gcn2 = GCN(512, 256, F.relu)\n",
        "        #self.fc1 = nn.Linear(256+300, 256)\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "\n",
        "\n",
        "    def forward(self, g):\n",
        "        \n",
        "        ##############################\n",
        "        # image\n",
        "        ##############################\n",
        "        h = g.ndata.pop('h')\n",
        "        h = self.gcn1(g, h)\n",
        "        h = self.gcn2(g, h)\n",
        "        g.ndata['h'] = h\n",
        "        \n",
        "        for i, graph in enumerate(dgl.unbatch(g)):\n",
        "            if i==0:\n",
        "                out_image = graph.ndata['h'][0].unsqueeze(0)\n",
        "            else:\n",
        "                out_image = torch.cat([out_image, graph.ndata['h'][0].unsqueeze(0)], dim=0)\n",
        "\n",
        "\n",
        "        # Calculate graph representation by averaging all the node representations.\n",
        "        #out_image = dgl.mean_nodes(g, 'h', 'w')  # wでの重み付き平均\n",
        "        # out_image = dgl.max_nodes(g, 'h')\n",
        "        \n",
        "        #out_image = torch.cat([out_image, class_labels_vec], dim=-1)\n",
        "        \n",
        "        out_image = F.dropout(out_image, p=0.3, training=self.training)\n",
        "        out_image = F.relu(self.fc1(out_image))\n",
        "        out_image = F.dropout(out_image, p=0.3, training=self.training)\n",
        "        out_image = F.relu(self.fc2(out_image))\n",
        "\n",
        "        \n",
        "        return out_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6MPYV8opJre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KDDModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(KDDModel, self).__init__()\n",
        "        self.model_name = 'KDDModel'\n",
        "\n",
        "        self.model_query = QueryModel()\n",
        "        self.model_image = ImageModel()\n",
        "\n",
        "\n",
        "    def forward(self, ids, token_type_ids, mask, g):\n",
        "        \n",
        "        out_query = self.model_query(ids, token_type_ids, mask)\n",
        "        out_image = self.model_image(g, class_labels_vec)\n",
        "\n",
        "        out = (out_query * out_image).squeeze()\n",
        "        #print(out.shape)\n",
        "        \n",
        "        return out.squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEph059mQ7zQ",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lD5g25aqG6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_loader, model, optimizer, criterion): #, scheduler):\n",
        "    model.train()\n",
        "    avg_loss = 0.\n",
        "    avg_score = 0.\n",
        "    for idx, (graph, features) in enumerate(tqdm(train_loader)):\n",
        "        ids_query = features['ids_query'].to(device)\n",
        "        mask_query = features['mask_query'].to(device)\n",
        "        token_type_ids_query = features['token_type_ids_query'].to(device)\n",
        "        labels = features['label'].to(device)\n",
        "\n",
        "        out = model(ids_query, token_type_ids_query, mask_query, graph)\n",
        "        \n",
        "        loss = criterion(out, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "\n",
        "        del ids_query,mask_query,token_type_ids_query,class_labels_vec,labels,out,loss\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "\n",
        "def test_model(test_loader, model):\n",
        "    model.eval()\n",
        "    \n",
        "    out_list = []   \n",
        "    with torch.no_grad():\n",
        "        for idx, (graph, features) in enumerate(tqdm(test_loader)):\n",
        "            ids_query = features['ids_query'].to(device)\n",
        "            mask_query = features['mask_query'].to(device)\n",
        "            token_type_ids_query = features['token_type_ids_query'].to(device)\n",
        "\n",
        "            out_query = model.model_query(ids_query, token_type_ids_query, mask_query)\n",
        "            out_image = model.model_image(graph, class_labels_vec)\n",
        "            out = F.cosine_similarity(out_query, out_image)\n",
        "\n",
        "            out_list.append(out)\n",
        "            del ids_query,mask_query,token_type_ids_query,out\n",
        "        \n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return out_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8RExWGGOwT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute dcg@k for a single sample\n",
        "def dcg_at_k(r, k):\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        return r[0] + np.sum(r[1:] / np.log2(np.arange(3, r.size + 2)))\n",
        "    return 0.\n",
        "\n",
        "\n",
        "# compute ndcg@k (dcg@k / idcg@k) for a single sample\n",
        "def get_ndcg(r, ref, k):\n",
        "    dcg_max = dcg_at_k(ref, k)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    dcg = dcg_at_k(r, k)\n",
        "    return dcg / dcg_max\n",
        "\n",
        "\n",
        "def make_score(df_test, out_list):\n",
        "    for i, out in enumerate(out_list):\n",
        "        if i==0:\n",
        "            out_array = out.squeeze()\n",
        "        else:\n",
        "            out_array = torch.cat([out_array, out.squeeze()], dim=-1)\n",
        "\n",
        "    out_array = out_array.cpu().detach().numpy()\n",
        "    df_test['score'] = out_array\n",
        "    \n",
        "    # sort and group by\n",
        "    df_test = df_test.sort_values(by=\"score\", ascending=False)\n",
        "    grouped = df_test.groupby(\"query_id\").head(5)\n",
        "    \n",
        "    predictions = {}\n",
        "    for i, q_id in enumerate(tqdm(grouped['query_id'].unique())):\n",
        "        predictions[f'{q_id}'] = grouped.loc[(grouped['query_id']==q_id), 'product_id'].values.astype(str)\n",
        "    \n",
        "    \n",
        "    # read ground-truth\n",
        "    reference = json.load(open(DATA_DIR+'valid/valid_answer.json'))\n",
        "\n",
        "    # compute score for each query\n",
        "    k = 5\n",
        "    score_sum = 0.\n",
        "    for qid in reference.keys():\n",
        "        ground_truth_ids = set([str(pid) for pid in reference[qid]])\n",
        "        ref_vec = [1.0] * len(ground_truth_ids)\n",
        "        pred_vec = [1.0 if pid in ground_truth_ids else 0.0 for pid in predictions[qid]]\n",
        "        score_sum += get_ndcg(pred_vec, ref_vec, k)\n",
        "    # the higher score, the better\n",
        "    score = score_sum / len(reference)\n",
        "    \n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQKLYducDw3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KDDModel().to(device)\n",
        "\n",
        "# if device == 'cuda':\n",
        "#     model = torch.nn.DataParallel(model) # make parallel\n",
        "#     cudnn.benchmark = True\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "#criterion = nn.CosineSimilarity()\n",
        "#criterion = nn.CosineEmbeddingLoss()\n",
        "criterion = losses.TripletMarginLoss(margin=0.1)\n",
        "\n",
        "loss_list_epoch_train = []\n",
        "score_list_epoch_valid = []\n",
        "score_best = 0\n",
        "patience = 0\n",
        "for epoch in range(20):\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    start_time   = time.time()\n",
        "\n",
        "    dataset_train = KDDDataset(train, train_mode=True)\n",
        "    dataset_valid = KDDDataset(valid, train_mode=False)\n",
        "    train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True, num_workers=0, drop_last=True, collate_fn=collate)\n",
        "    valid_loader = DataLoader(dataset_valid, batch_size=128, shuffle=False, num_workers=0, drop_last=True, collate_fn=collate_test)\n",
        "    #scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=config.warmup, num_training_steps=config.epochs*len(train_loader))\n",
        "\n",
        "    loss_train = train_model(train_loader, model, optimizer, criterion)#, scheduler)\n",
        "    out_valid = test_model(valid_loader, model)\n",
        "    score_valid = make_score(valid, out_valid)\n",
        "\n",
        "    loss_list_epoch_train.append(loss_train)\n",
        "    score_list_epoch_valid.append(score_valid)\n",
        "\n",
        "    logger.info(f'Epoch {(epoch+1)}, train_loss: {loss_train}, valid_score: {score_valid}, time: {(time.time()-start_time)}')\n",
        "\n",
        "    # Eearly Stopping\n",
        "    if score_valid > score_best:\n",
        "        score_best = score_valid\n",
        "        best_param = model.state_dict()\n",
        "        torch.save(best_param, MODEL_DIR+f'best_param.pt')\n",
        "        patience = 0\n",
        "    else:\n",
        "        patience += 1\n",
        "        if patience >= 2:\n",
        "            del train_loader, valid_loader, loss_train, out_valid\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            break\n",
        "\n",
        "    del train_loader, valid_loader, loss_train, out_valid\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFQxlZT--VyT",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD34AvNo_L8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KDDModel().to(device)\n",
        "model.load_state_dict(torch.load(MODEL_DIR+f'best_param.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGVfkoEf_Lpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_submit_df(df_test, model_query, model_image):\n",
        "    dataset_test = KDDDataset(df_test, train_mode=False)\n",
        "    test_loader = DataLoader(dataset_test, batch_size=128, shuffle=False, num_workers=0, drop_last=True, collate_fn=collate_test)\n",
        "    out_list = test_model(test_loader, model_query, model_image)\n",
        "\n",
        "    for i, out in enumerate(out_list):\n",
        "        if i==0:\n",
        "            out_array = out.squeeze()\n",
        "        else:\n",
        "            out_array = torch.cat([out_array, out.squeeze()], dim=-1)\n",
        "\n",
        "    out_array = out_array.cpu().detach().numpy()\n",
        "    df_test['score'] = out_array\n",
        "    \n",
        "    # sort and group by\n",
        "    df_test = df_test.sort_values(by=\"score\", ascending=False)\n",
        "    grouped = df_test.groupby(\"query_id\").head(5)\n",
        "    \n",
        "    submit_df = pd.DataFrame(columns=['query-id','product1','product2','product3','product4','product5'])\n",
        "    for i, q_id in enumerate(tqdm(grouped['query_id'].unique())):\n",
        "        submit_df.loc[i, 'query-id'] = q_id\n",
        "        submit_df.iloc[i, 1:] = grouped.loc[(grouped['query_id']==q_id), 'product_id'].values\n",
        "    submit_df = submit_df.astype(int)\n",
        "    submit_df = submit_df.sort_values(by='query-id')\n",
        "    submit_df = submit_df.reset_index(drop=True)\n",
        "    \n",
        "    return submit_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JiU01lb_LZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_df = make_submit_df(testA, model)\n",
        "submit_df.to_csv(SUBMIT_DIR+'submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSrMWqt4B_Ez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}